{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, json, time\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import plotting\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from utils import imread, img_data_2_mini_batch, imgs2batch\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# from naive import EncDec\n",
    "from attention import EncDec as FuseAttEncDec\n",
    "# from rnn_att import EncDec\n",
    "from data_loader import VQADataSet\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torchvision import transforms\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/data_10000.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:26<00:00, 375.69it/s]\n",
      "100%|██████████| 9873/9873 [00:00<00:00, 301304.33it/s]\n",
      "100%|██████████| 9873/9873 [00:02<00:00, 4441.94it/s]\n",
      "100%|██████████| 9873/9873 [00:00<00:00, 19052.79it/s]\n",
      "100%|██████████| 9873/9873 [00:00<00:00, 212985.60it/s]\n",
      "100%|██████████| 1658/1658 [00:00<00:00, 49976.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VQADataSet init time: 37.085965156555176\n",
      "writing to ./data/data_10000.pkl\n"
     ]
    }
   ],
   "source": [
    "N = 5000\n",
    "dataset_filename = \"./data/data_{}.pkl\".format(N)\n",
    "dataset = None\n",
    "print(dataset_filename)\n",
    "if (os.path.exists(dataset_filename)):\n",
    "    with open(dataset_filename, 'rb') as handle:\n",
    "        print(\"reading from \" + dataset_filename)\n",
    "        dataset = pickle.load(handle)\n",
    "else:\n",
    "    dataset = VQADataSet(Q=N)\n",
    "    with open(dataset_filename, 'wb') as handle:\n",
    "        print(\"writing to \" + dataset_filename)\n",
    "        pickle.dump(dataset, handle)\n",
    "\n",
    "assert(dataset is not None)\n",
    "def debug(v,q,a):\n",
    "    print('\\nV: {}\\nQ: {}\\nA: {}'.format(v.shape, q.shape, a.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3356 1658\n"
     ]
    }
   ],
   "source": [
    "embed_size        = 256\n",
    "hidden_size       = 256\n",
    "batch_size        = 50\n",
    "ques_vocab_size   = len(dataset.vocab['question'])\n",
    "ans_vocab_size    = len(dataset.vocab['answer'])\n",
    "num_layers        = 1\n",
    "n_epochs          = 30\n",
    "learning_rate     = 0.001\n",
    "momentum          = 0.98\n",
    "attention_size    = 26\n",
    "debug             = False\n",
    "\n",
    "print(ques_vocab_size, ans_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(data_loader, model, criterion, optimizer, batch_size, training=False,\n",
    "              epoch = 0, total_loss_over_epochs=[], scores_over_epochs=[]):\n",
    "    running_loss = 0.\n",
    "    final_labels, final_preds = [], []\n",
    "    scores, losses = [], []\n",
    "    if data_loader is None:\n",
    "        return\n",
    "    \n",
    "    run_type = None\n",
    "    if training:\n",
    "        run_type = 'train'\n",
    "        model.train()\n",
    "    else:\n",
    "        run_type = 'test'\n",
    "        model.eval()\n",
    "    \n",
    "    for i, minibatch in enumerate(data_loader):\n",
    "        # extract minibatch\n",
    "        t0 = time.time()\n",
    "        idxs, v, q, a, q_len = minibatch\n",
    "        \n",
    "        # convert torch's DataLoader output to proper format.\n",
    "        # torch gives a List[Tensor_1, ... ] where tensor has been transposed. \n",
    "        # batchify transposes back.`\n",
    "        v = v.to(device)\n",
    "        q = VQADataSet.batchify_questions(q).to(device)\n",
    "        a = a.to(device)\n",
    "\n",
    "        logits = model(v, q, q_len)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "#         loss = criterion(logits, a)\n",
    "        loss = F.nll_loss(logits, a)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "#         score = metrics.precision_recall_fscore_support(preds.tolist(),\n",
    "#                                                         a.tolist(),\n",
    "#                                                         average='weighted')\n",
    "        score = metrics.accuracy_score(preds.tolist(),a.tolist())\n",
    "    \n",
    "        scores.append(score)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        loss_key = '{}_loss'.format(run_type)\n",
    "        total_loss_over_epochs['{}_loss'.format(run_type)].append(loss)\n",
    "        scores_over_epochs['{}_scores'.format(run_type)].append(score)\n",
    "        \n",
    "        if training and optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "   \n",
    "        final_labels += a.tolist()\n",
    "        final_preds  += preds.tolist()\n",
    "        if i%10==0:\n",
    "            score = np.mean(scores)\n",
    "            print(\"Epoch {}: {} Loss: {} Score: {} t: {}\".format(epoch, run_type,loss, score, time.time()-t0))\n",
    "#             plotting.plot_score_over_n_epochs(scores_over_epochs, score_type='precision', fig_size=(7,3))\n",
    "#             plotting.plot_loss_over_n_epochs(total_loss_over_epochs, hard_key=loss_key, fig_size=(7, 3))\n",
    "            \n",
    "    return running_loss, final_labels, final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 50 shuffle: True\n",
      "batch_size: 50 shuffle: False\n",
      "model built, start training.\n",
      "Epoch 0: train Loss: 7.39285945892334 Score: 0.0 t: 0.3493924140930176\n",
      "Epoch 0: train Loss: 5.687780380249023 Score: 0.12000000000000002 t: 0.31960606575012207\n",
      "Epoch 0: train Loss: 5.581486701965332 Score: 0.14190476190476192 t: 0.32895612716674805\n",
      "Epoch 0: train Loss: 5.432222843170166 Score: 0.15548387096774194 t: 0.3270988464355469\n",
      "Epoch 0: train Loss: 4.512545108795166 Score: 0.16439024390243903 t: 0.32564568519592285\n",
      "Epoch 0: train Loss: 5.237973690032959 Score: 0.16627450980392156 t: 0.34931063652038574\n",
      "Epoch 0: train Loss: 4.351251125335693 Score: 0.16721311475409834 t: 0.32316040992736816\n",
      "Epoch 0: train Loss: 5.537405490875244 Score: 0.1712676056338028 t: 0.32485294342041016\n",
      "Epoch 0: train Loss: 4.251253128051758 Score: 0.17135802469135802 t: 0.32932615280151367\n",
      "Epoch 0: train Loss: 4.707014560699463 Score: 0.17076923076923078 t: 0.32668113708496094\n",
      "Epoch 0: train Loss: 5.310774326324463 Score: 0.17168316831683167 t: 0.3229079246520996\n",
      "Epoch 0: train Loss: 5.138906478881836 Score: 0.1717117117117117 t: 0.33478689193725586\n",
      "Epoch 0: train Loss: 4.626819133758545 Score: 0.1740495867768595 t: 0.3225080966949463\n",
      "Epoch 0: train Loss: 4.846494197845459 Score: 0.17465648854961835 t: 0.32781481742858887\n",
      "Epoch 0: train Loss: 4.777632236480713 Score: 0.17560283687943265 t: 0.3273735046386719\n",
      "Epoch 0: train Loss: 4.8257012367248535 Score: 0.17748344370860925 t: 0.3223707675933838\n",
      "Epoch 0: train Loss: 4.485658645629883 Score: 0.1786335403726708 t: 0.32421231269836426\n",
      "Epoch 0: test Loss: 1.998762845993042 Score: 0.02 t: 0.29743003845214844\n",
      "Epoch 0: test Loss: 0.6122073531150818 Score: 0.31272727272727274 t: 0.30115675926208496\n",
      "Epoch 0: test Loss: 2.72432017326355 Score: 0.3742857142857143 t: 0.3003368377685547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 1/30 [06:16<3:01:51, 376.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#==##==##==##==##==##==##==#epoch: 0#==##==##==##==##==##==##==#\n",
      "TEST ACC: 0.2677006068779501\n",
      "#==##==##==##==##==##==##==#time: 376.2606565952301#==##==##==##==##==##==##==#\n",
      "\n",
      "Epoch 1: train Loss: 4.891851425170898 Score: 0.14 t: 0.32692670822143555\n",
      "Epoch 1: train Loss: 4.433326244354248 Score: 0.18727272727272723 t: 0.3278353214263916\n",
      "Epoch 1: train Loss: 4.934946060180664 Score: 0.18666666666666668 t: 0.33093976974487305\n",
      "Epoch 1: train Loss: 4.339747428894043 Score: 0.2 t: 0.32828855514526367\n",
      "Epoch 1: train Loss: 3.859689950942993 Score: 0.20146341463414633 t: 0.3282618522644043\n",
      "Epoch 1: train Loss: 4.790663719177246 Score: 0.19999999999999998 t: 0.3303954601287842\n",
      "Epoch 1: train Loss: 4.880555629730225 Score: 0.20360655737704922 t: 0.32822322845458984\n",
      "Epoch 1: train Loss: 4.5336012840271 Score: 0.20760563380281688 t: 0.32785463333129883\n",
      "Epoch 1: train Loss: 3.7525463104248047 Score: 0.20814814814814814 t: 0.33019089698791504\n",
      "Epoch 1: train Loss: 4.6499505043029785 Score: 0.209010989010989 t: 0.328324556350708\n",
      "Epoch 1: train Loss: 5.138787269592285 Score: 0.2085148514851485 t: 0.3313164710998535\n",
      "Epoch 1: train Loss: 4.047595024108887 Score: 0.2097297297297298 t: 0.3295917510986328\n",
      "Epoch 1: train Loss: 4.188271522521973 Score: 0.21090909090909093 t: 0.3285994529724121\n",
      "Epoch 1: train Loss: 3.9981820583343506 Score: 0.2111450381679389 t: 0.3275022506713867\n",
      "Epoch 1: train Loss: 3.1030936241149902 Score: 0.2117730496453901 t: 0.3367922306060791\n",
      "Epoch 1: train Loss: 3.7478132247924805 Score: 0.21218543046357616 t: 0.3273000717163086\n",
      "Epoch 1: train Loss: 4.451133728027344 Score: 0.21167701863354035 t: 0.32918214797973633\n",
      "Epoch 1: test Loss: 1.5042405128479004 Score: 0.62 t: 0.29763150215148926\n",
      "Epoch 1: test Loss: 0.8217085003852844 Score: 0.5327272727272727 t: 0.3016355037689209\n",
      "Epoch 1: test Loss: 2.2254128456115723 Score: 0.41428571428571426 t: 0.3012866973876953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 2/30 [11:55<2:50:24, 365.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#==##==##==##==##==##==##==#epoch: 1#==##==##==##==##==##==##==#\n",
      "TEST ACC: 0.2980445043830074\n",
      "#==##==##==##==##==##==##==#time: 339.31025195121765#==##==##==##==##==##==##==#\n",
      "\n",
      "Epoch 2: train Loss: 4.0269060134887695 Score: 0.28 t: 0.3264646530151367\n",
      "Epoch 2: train Loss: 3.841561794281006 Score: 0.24363636363636365 t: 0.33307981491088867\n",
      "Epoch 2: train Loss: 4.018762111663818 Score: 0.21428571428571427 t: 0.33028316497802734\n",
      "Epoch 2: train Loss: 3.989952325820923 Score: 0.20903225806451614 t: 0.3360261917114258\n",
      "Epoch 2: train Loss: 4.39192008972168 Score: 0.21463414634146338 t: 0.3320479393005371\n",
      "Epoch 2: train Loss: 4.289855480194092 Score: 0.21568627450980396 t: 0.32895493507385254\n",
      "Epoch 2: train Loss: 4.147404670715332 Score: 0.21573770491803276 t: 0.32976388931274414\n",
      "Epoch 2: train Loss: 5.272123336791992 Score: 0.21633802816901407 t: 0.33563995361328125\n",
      "Epoch 2: train Loss: 4.605485439300537 Score: 0.21333333333333335 t: 0.3338205814361572\n",
      "Epoch 2: train Loss: 4.042288303375244 Score: 0.21208791208791208 t: 0.326519250869751\n",
      "Epoch 2: train Loss: 5.457644462585449 Score: 0.20950495049504955 t: 0.3322937488555908\n",
      "Epoch 2: train Loss: 3.9742703437805176 Score: 0.20918918918918922 t: 0.3292546272277832\n",
      "Epoch 2: train Loss: 4.430728912353516 Score: 0.21057851239669423 t: 0.32677340507507324\n",
      "Epoch 2: train Loss: 3.6249289512634277 Score: 0.21038167938931296 t: 0.32993316650390625\n",
      "Epoch 2: train Loss: 4.20817756652832 Score: 0.2119148936170213 t: 0.330214262008667\n",
      "Epoch 2: train Loss: 4.045754909515381 Score: 0.21496688741721856 t: 0.32527780532836914\n",
      "Epoch 2: train Loss: 3.7513058185577393 Score: 0.21701863354037265 t: 0.33493900299072266\n",
      "Epoch 2: test Loss: 1.4557360410690308 Score: 0.8 t: 0.2992372512817383\n",
      "Epoch 2: test Loss: 0.9172329902648926 Score: 0.649090909090909 t: 0.30564165115356445\n",
      "Epoch 2: test Loss: 2.22975754737854 Score: 0.44190476190476197 t: 0.3002128601074219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 3/30 [17:27<2:39:51, 355.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#==##==##==##==##==##==##==#epoch: 2#==##==##==##==##==##==##==#\n",
      "TEST ACC: 0.3209710047201618\n",
      "#==##==##==##==##==##==##==#time: 332.10189986228943#==##==##==##==##==##==##==#\n",
      "\n",
      "Epoch 3: train Loss: 3.661611557006836 Score: 0.22 t: 0.3286287784576416\n",
      "Epoch 3: train Loss: 3.7202508449554443 Score: 0.23636363636363633 t: 0.33376526832580566\n",
      "Epoch 3: train Loss: 4.112190246582031 Score: 0.22095238095238098 t: 0.33170509338378906\n",
      "Epoch 3: train Loss: 4.363531112670898 Score: 0.21548387096774196 t: 0.32670068740844727\n",
      "Epoch 3: train Loss: 4.088739395141602 Score: 0.22341463414634147 t: 0.328502893447876\n",
      "Epoch 3: train Loss: 3.9716506004333496 Score: 0.2223529411764706 t: 0.3307828903198242\n",
      "Epoch 3: train Loss: 4.042126178741455 Score: 0.22688524590163933 t: 0.3247208595275879\n",
      "Epoch 3: train Loss: 3.8696413040161133 Score: 0.22309859154929576 t: 0.3323087692260742\n",
      "Epoch 3: train Loss: 4.0373921394348145 Score: 0.21901234567901237 t: 0.335939884185791\n",
      "Epoch 3: train Loss: 3.9072539806365967 Score: 0.21846153846153846 t: 0.3267538547515869\n",
      "Epoch 3: train Loss: 3.3222625255584717 Score: 0.21861386138613864 t: 0.33612942695617676\n",
      "Epoch 3: train Loss: 4.120110988616943 Score: 0.2156756756756757 t: 0.3296637535095215\n",
      "Epoch 3: train Loss: 4.245723724365234 Score: 0.21719008264462814 t: 0.32489609718322754\n",
      "Epoch 3: train Loss: 3.680107355117798 Score: 0.21862595419847328 t: 0.3359549045562744\n",
      "Epoch 3: train Loss: 4.2224531173706055 Score: 0.2171631205673759 t: 0.3347795009613037\n",
      "Epoch 3: train Loss: 4.177628993988037 Score: 0.21894039735099338 t: 0.3268885612487793\n",
      "Epoch 3: train Loss: 3.965541124343872 Score: 0.21987577639751557 t: 0.33847880363464355\n",
      "Epoch 3: test Loss: 1.647874116897583 Score: 0.06 t: 0.29903578758239746\n",
      "Epoch 3: test Loss: 0.6976149678230286 Score: 0.31636363636363635 t: 0.3048989772796631\n",
      "Epoch 3: test Loss: 2.1301558017730713 Score: 0.4219047619047618 t: 0.3038451671600342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 4/30 [22:13<2:24:55, 334.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#==##==##==##==##==##==##==#epoch: 3#==##==##==##==##==##==##==#\n",
      "TEST ACC: 0.3115306810519218\n",
      "#==##==##==##==##==##==##==#time: 285.877991437912#==##==##==##==##==##==##==#\n",
      "\n",
      "Epoch 4: train Loss: 3.2138211727142334 Score: 0.26 t: 0.33054685592651367\n",
      "Epoch 4: train Loss: 3.8079652786254883 Score: 0.23272727272727278 t: 0.3281865119934082\n",
      "Epoch 4: train Loss: 3.6952459812164307 Score: 0.22095238095238098 t: 0.32869672775268555\n",
      "Epoch 4: train Loss: 4.105656623840332 Score: 0.21999999999999997 t: 0.3316481113433838\n",
      "Epoch 4: train Loss: 4.517735481262207 Score: 0.20975609756097566 t: 0.3294942378997803\n",
      "Epoch 4: train Loss: 4.643342018127441 Score: 0.21058823529411766 t: 0.3300297260284424\n",
      "Epoch 4: train Loss: 4.008633613586426 Score: 0.2131147540983607 t: 0.32985401153564453\n",
      "Epoch 4: train Loss: 4.091020107269287 Score: 0.21070422535211267 t: 0.328441858291626\n",
      "Epoch 4: train Loss: 3.8674819469451904 Score: 0.21432098765432098 t: 0.33176517486572266\n",
      "Epoch 4: train Loss: 4.120925426483154 Score: 0.21428571428571427 t: 0.3334059715270996\n",
      "Epoch 4: train Loss: 4.254695892333984 Score: 0.2142574257425743 t: 0.32663559913635254\n",
      "Epoch 4: train Loss: 4.139380931854248 Score: 0.21765765765765763 t: 0.33357810974121094\n",
      "Epoch 4: train Loss: 3.9492082595825195 Score: 0.22 t: 0.32880425453186035\n",
      "Epoch 4: train Loss: 4.2655816078186035 Score: 0.2187786259541985 t: 0.33968448638916016\n",
      "Epoch 4: train Loss: 3.9067511558532715 Score: 0.2173049645390071 t: 0.3371715545654297\n",
      "Epoch 4: train Loss: 3.917722463607788 Score: 0.2166887417218543 t: 0.3257291316986084\n",
      "Epoch 4: train Loss: 3.664761543273926 Score: 0.2181366459627329 t: 0.33159852027893066\n",
      "Epoch 4: test Loss: 1.625944972038269 Score: 0.0 t: 0.2984302043914795\n",
      "Epoch 4: test Loss: 0.6126049160957336 Score: 0.3054545454545454 t: 0.30193281173706055\n",
      "Epoch 4: test Loss: 2.069859266281128 Score: 0.4247619047619048 t: 0.3053014278411865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 5/30 [27:11<2:14:45, 323.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#==##==##==##==##==##==##==#epoch: 4#==##==##==##==##==##==##==#\n",
      "TEST ACC: 0.3135536075522589\n",
      "#==##==##==##==##==##==##==#time: 297.72498178482056#==##==##==##==##==##==##==#\n",
      "\n",
      "Epoch 5: train Loss: 3.55867075920105 Score: 0.32 t: 0.3252427577972412\n",
      "Epoch 5: train Loss: 4.5609211921691895 Score: 0.2254545454545455 t: 0.33093786239624023\n",
      "Epoch 5: train Loss: 3.6125924587249756 Score: 0.22 t: 0.3305380344390869\n",
      "Epoch 5: train Loss: 4.677506923675537 Score: 0.2103225806451613 t: 0.32633543014526367\n",
      "Epoch 5: train Loss: 3.385716199874878 Score: 0.21463414634146338 t: 0.332721471786499\n",
      "Epoch 5: train Loss: 3.9503326416015625 Score: 0.21882352941176467 t: 0.33729982376098633\n",
      "Epoch 5: train Loss: 4.440182209014893 Score: 0.22098360655737706 t: 0.3265097141265869\n",
      "Epoch 5: train Loss: 5.016791820526123 Score: 0.22450704225352108 t: 0.3364720344543457\n",
      "Epoch 5: train Loss: 4.784875392913818 Score: 0.2249382716049383 t: 0.3367791175842285\n",
      "Epoch 5: train Loss: 3.707854986190796 Score: 0.22549450549450553 t: 0.32828664779663086\n",
      "Epoch 5: train Loss: 4.599761962890625 Score: 0.221980198019802 t: 0.3355231285095215\n",
      "Epoch 5: train Loss: 3.5837464332580566 Score: 0.21711711711711718 t: 0.3294064998626709\n",
      "Epoch 5: train Loss: 4.020282745361328 Score: 0.2155371900826447 t: 0.3314688205718994\n",
      "Epoch 5: train Loss: 3.4979088306427 Score: 0.21648854961832062 t: 0.33818888664245605\n",
      "Epoch 5: train Loss: 4.2191877365112305 Score: 0.2187234042553191 t: 0.32906413078308105\n",
      "Epoch 5: train Loss: 3.964712142944336 Score: 0.2194701986754967 t: 0.32869553565979004\n",
      "Epoch 5: train Loss: 4.223555088043213 Score: 0.22037267080745343 t: 0.3291769027709961\n",
      "Epoch 5: test Loss: 1.534810185432434 Score: 0.04 t: 0.3012099266052246\n",
      "Epoch 5: test Loss: 0.7485940456390381 Score: 0.34727272727272723 t: 0.3017575740814209\n",
      "Epoch 5: test Loss: 2.146547794342041 Score: 0.4342857142857143 t: 0.304746150970459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 6/30 [31:29<2:01:36, 304.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#==##==##==##==##==##==##==#epoch: 5#==##==##==##==##==##==##==#\n",
      "TEST ACC: 0.3189480782198247\n",
      "#==##==##==##==##==##==##==#time: 258.6817171573639#==##==##==##==##==##==##==#\n",
      "\n",
      "Epoch 6: train Loss: 3.797297716140747 Score: 0.2 t: 0.33276963233947754\n",
      "Epoch 6: train Loss: 3.606513261795044 Score: 0.24727272727272728 t: 0.32701778411865234\n",
      "Epoch 6: train Loss: 4.2806172370910645 Score: 0.24380952380952386 t: 0.32970738410949707\n",
      "Epoch 6: train Loss: 4.223718643188477 Score: 0.23935483870967741 t: 0.3299129009246826\n",
      "Epoch 6: train Loss: 4.132095813751221 Score: 0.224390243902439 t: 0.3305537700653076\n",
      "Epoch 6: train Loss: 4.297580242156982 Score: 0.2227450980392157 t: 0.33347535133361816\n",
      "Epoch 6: train Loss: 3.5074546337127686 Score: 0.22655737704918036 t: 0.3285198211669922\n",
      "Epoch 6: train Loss: 2.9098567962646484 Score: 0.22591549295774646 t: 0.33351945877075195\n",
      "Epoch 6: train Loss: 3.9100191593170166 Score: 0.22567901234567903 t: 0.3344740867614746\n",
      "Epoch 6: train Loss: 3.8457345962524414 Score: 0.2257142857142857 t: 0.33032798767089844\n",
      "Epoch 6: train Loss: 4.512124061584473 Score: 0.2235643564356436 t: 0.33229827880859375\n",
      "Epoch 6: train Loss: 4.31992769241333 Score: 0.22360360360360365 t: 0.3347897529602051\n",
      "Epoch 6: train Loss: 4.365175247192383 Score: 0.223305785123967 t: 0.3294084072113037\n",
      "Epoch 6: train Loss: 3.8639206886291504 Score: 0.22152671755725192 t: 0.32904934883117676\n",
      "Epoch 6: train Loss: 3.153945207595825 Score: 0.22354609929078015 t: 0.33722567558288574\n",
      "Epoch 6: train Loss: 3.0600709915161133 Score: 0.22543046357615898 t: 0.33045244216918945\n",
      "Epoch 6: train Loss: 3.5064868927001953 Score: 0.2243478260869565 t: 0.33124876022338867\n",
      "Epoch 6: test Loss: 1.5464367866516113 Score: 0.12 t: 0.301802396774292\n",
      "Epoch 6: test Loss: 0.7942663431167603 Score: 0.3327272727272727 t: 0.30454301834106445\n",
      "Epoch 6: test Loss: 2.1839284896850586 Score: 0.42095238095238086 t: 0.3092367649078369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 7/30 [34:38<1:43:18, 269.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#==##==##==##==##==##==##==#epoch: 6#==##==##==##==##==##==##==#\n",
      "TEST ACC: 0.3115306810519218\n",
      "#==##==##==##==##==##==##==#time: 188.93000268936157#==##==##==##==##==##==##==#\n",
      "\n",
      "Epoch 7: train Loss: 4.173227310180664 Score: 0.18 t: 0.3277773857116699\n",
      "Epoch 7: train Loss: 3.0275046825408936 Score: 0.22727272727272727 t: 0.33722853660583496\n",
      "Epoch 7: train Loss: 4.8623552322387695 Score: 0.22095238095238098 t: 0.340442419052124\n",
      "Epoch 7: train Loss: 3.892443895339966 Score: 0.22258064516129036 t: 0.32753515243530273\n",
      "Epoch 7: train Loss: 3.6960654258728027 Score: 0.21951219512195122 t: 0.333981990814209\n",
      "Epoch 7: train Loss: 4.729180812835693 Score: 0.21999999999999997 t: 0.3296804428100586\n",
      "Epoch 7: train Loss: 3.8916027545928955 Score: 0.22557377049180327 t: 0.32820844650268555\n",
      "Epoch 7: train Loss: 3.6471927165985107 Score: 0.2247887323943662 t: 0.3334190845489502\n",
      "Epoch 7: train Loss: 4.18693733215332 Score: 0.22444444444444445 t: 0.33213186264038086\n",
      "Epoch 7: train Loss: 3.8832461833953857 Score: 0.22505494505494503 t: 0.329970121383667\n",
      "Epoch 7: train Loss: 3.6874868869781494 Score: 0.22732673267326733 t: 0.32921624183654785\n",
      "Epoch 7: train Loss: 3.4836230278015137 Score: 0.2254054054054054 t: 0.3328108787536621\n",
      "Epoch 7: train Loss: 3.915128469467163 Score: 0.2266115702479339 t: 0.3289520740509033\n",
      "Epoch 7: train Loss: 3.3692145347595215 Score: 0.22778625954198473 t: 0.3364269733428955\n",
      "Epoch 7: train Loss: 3.3686890602111816 Score: 0.22539007092198585 t: 0.3300633430480957\n",
      "Epoch 7: train Loss: 4.3379597663879395 Score: 0.2247682119205298 t: 0.3329617977142334\n",
      "Epoch 7: train Loss: 4.3151469230651855 Score: 0.22509316770186336 t: 0.3399643898010254\n",
      "Epoch 7: test Loss: 1.3107753992080688 Score: 0.3 t: 0.30306434631347656\n",
      "Epoch 7: test Loss: 0.7569361925125122 Score: 0.42909090909090913 t: 0.30257463455200195\n",
      "Epoch 7: test Loss: 1.9132513999938965 Score: 0.43238095238095237 t: 0.30525636672973633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 8/30 [37:57<1:31:00, 248.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#==##==##==##==##==##==##==#epoch: 7#==##==##==##==##==##==##==#\n",
      "TEST ACC: 0.3263654753877276\n",
      "#==##==##==##==##==##==##==#time: 198.56989550590515#==##==##==##==##==##==##==#\n",
      "\n",
      "Epoch 8: train Loss: 3.6335394382476807 Score: 0.26 t: 0.3283834457397461\n",
      "Epoch 8: train Loss: 4.4375319480896 Score: 0.22909090909090912 t: 0.3274118900299072\n",
      "Epoch 8: train Loss: 4.641793727874756 Score: 0.2180952380952381 t: 0.3303983211517334\n",
      "Epoch 8: train Loss: 4.708625316619873 Score: 0.21806451612903224 t: 0.32627320289611816\n",
      "Epoch 8: train Loss: 4.198715686798096 Score: 0.22243902439024393 t: 0.32794618606567383\n",
      "Epoch 8: train Loss: 3.5739939212799072 Score: 0.22352941176470592 t: 0.33109307289123535\n",
      "Epoch 8: train Loss: 4.027577877044678 Score: 0.22360655737704915 t: 0.3302733898162842\n",
      "Epoch 8: train Loss: 3.446059226989746 Score: 0.2228169014084507 t: 0.32866930961608887\n",
      "Epoch 8: train Loss: 3.0558362007141113 Score: 0.2246913580246913 t: 0.330761194229126\n",
      "Epoch 8: train Loss: 4.377926349639893 Score: 0.22175824175824174 t: 0.3284950256347656\n",
      "Epoch 8: train Loss: 3.9185590744018555 Score: 0.22435643564356436 t: 0.33219051361083984\n",
      "Epoch 8: train Loss: 3.967294216156006 Score: 0.2255855855855856 t: 0.3329305648803711\n",
      "Epoch 8: train Loss: 4.293804168701172 Score: 0.2252892561983471 t: 0.32784199714660645\n",
      "Epoch 8: train Loss: 3.6490976810455322 Score: 0.22519083969465647 t: 0.3331584930419922\n",
      "Epoch 8: train Loss: 4.328990459442139 Score: 0.22368794326241134 t: 0.33217430114746094\n",
      "Epoch 8: train Loss: 4.100631237030029 Score: 0.2235761589403974 t: 0.33794498443603516\n",
      "Epoch 8: train Loss: 3.33113431930542 Score: 0.22534161490683227 t: 0.3290286064147949\n",
      "Epoch 8: test Loss: 1.3711416721343994 Score: 0.54 t: 0.29949307441711426\n",
      "Epoch 8: test Loss: 0.8019275069236755 Score: 0.5181818181818183 t: 0.3038456439971924\n",
      "Epoch 8: test Loss: 1.8206689357757568 Score: 0.4333333333333333 t: 0.3060154914855957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 9/30 [41:21<1:22:15, 235.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#==##==##==##==##==##==##==#epoch: 8#==##==##==##==##==##==##==#\n",
      "TEST ACC: 0.3263654753877276\n",
      "#==##==##==##==##==##==##==#time: 204.18942260742188#==##==##==##==##==##==##==#\n",
      "\n",
      "Epoch 9: train Loss: 3.7359464168548584 Score: 0.2 t: 0.32738542556762695\n",
      "Epoch 9: train Loss: 3.796734094619751 Score: 0.22909090909090904 t: 0.33394408226013184\n",
      "Epoch 9: train Loss: 3.7428269386291504 Score: 0.22095238095238093 t: 0.33145737648010254\n",
      "Epoch 9: train Loss: 3.3713858127593994 Score: 0.22774193548387098 t: 0.32898712158203125\n",
      "Epoch 9: train Loss: 4.0143723487854 Score: 0.22731707317073177 t: 0.33182215690612793\n",
      "Epoch 9: train Loss: 3.90407133102417 Score: 0.2286274509803922 t: 0.32985901832580566\n",
      "Epoch 9: train Loss: 4.211452484130859 Score: 0.2278688524590164 t: 0.33458781242370605\n",
      "Epoch 9: train Loss: 3.341634511947632 Score: 0.2284507042253521 t: 0.3273169994354248\n",
      "Epoch 9: train Loss: 3.175774335861206 Score: 0.22543209876543213 t: 0.33247923851013184\n",
      "Epoch 9: train Loss: 4.212179660797119 Score: 0.22549450549450548 t: 0.32627344131469727\n",
      "Epoch 9: train Loss: 3.3733456134796143 Score: 0.22732673267326742 t: 0.32953429222106934\n",
      "Epoch 9: train Loss: 4.327033042907715 Score: 0.2279279279279279 t: 0.33162832260131836\n",
      "Epoch 9: train Loss: 3.2382402420043945 Score: 0.22776859504132235 t: 0.33377552032470703\n",
      "Epoch 9: train Loss: 3.8009250164031982 Score: 0.22748091603053433 t: 0.33774876594543457\n",
      "Epoch 9: train Loss: 3.179417133331299 Score: 0.22822695035460994 t: 0.33461642265319824\n",
      "Epoch 9: train Loss: 3.4026224613189697 Score: 0.22874172185430458 t: 0.3315393924713135\n",
      "Epoch 9: train Loss: 3.7650158405303955 Score: 0.22931677018633542 t: 0.33266186714172363\n",
      "Epoch 9: test Loss: 1.4802846908569336 Score: 0.44 t: 0.29882287979125977\n",
      "Epoch 9: test Loss: 0.7987415790557861 Score: 0.49272727272727274 t: 0.3054385185241699\n",
      "Epoch 9: test Loss: 1.9498165845870972 Score: 0.4352380952380952 t: 0.30329227447509766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 10/30 [45:55<1:22:12, 246.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#==##==##==##==##==##==##==#epoch: 9#==##==##==##==##==##==##==#\n",
      "TEST ACC: 0.32838840188806473\n",
      "#==##==##==##==##==##==##==#time: 273.6767108440399#==##==##==##==##==##==##==#\n",
      "\n",
      "Epoch 10: train Loss: 3.9745044708251953 Score: 0.32 t: 0.3289492130279541\n",
      "Epoch 10: train Loss: 3.4076616764068604 Score: 0.2254545454545455 t: 0.32998204231262207\n",
      "Epoch 10: train Loss: 3.479351282119751 Score: 0.22571428571428573 t: 0.3307318687438965\n",
      "Epoch 10: train Loss: 4.4731669425964355 Score: 0.2232258064516129 t: 0.3303861618041992\n",
      "Epoch 10: train Loss: 4.122232437133789 Score: 0.22048780487804875 t: 0.32976746559143066\n",
      "Epoch 10: train Loss: 3.572843074798584 Score: 0.22627450980392153 t: 0.3296699523925781\n",
      "Epoch 10: train Loss: 3.6775522232055664 Score: 0.22688524590163933 t: 0.3302309513092041\n",
      "Epoch 10: train Loss: 4.19441556930542 Score: 0.22647887323943663 t: 0.33347296714782715\n",
      "Epoch 10: train Loss: 3.559814453125 Score: 0.23037037037037036 t: 0.3324861526489258\n",
      "Epoch 10: train Loss: 3.159466505050659 Score: 0.23472527472527477 t: 0.3265111446380615\n",
      "Epoch 10: train Loss: 3.8374276161193848 Score: 0.23366336633663368 t: 0.3285844326019287\n",
      "Epoch 10: train Loss: 3.409743070602417 Score: 0.23765765765765767 t: 0.33078527450561523\n",
      "Epoch 10: train Loss: 3.769742488861084 Score: 0.23669421487603307 t: 0.32851362228393555\n",
      "Epoch 10: train Loss: 3.447178602218628 Score: 0.23709923664122137 t: 0.3292996883392334\n",
      "Epoch 10: train Loss: 4.017735004425049 Score: 0.2357446808510638 t: 0.3286612033843994\n",
      "Epoch 10: train Loss: 3.6269097328186035 Score: 0.23774834437086095 t: 0.32688379287719727\n",
      "Epoch 10: train Loss: 3.9026730060577393 Score: 0.23763975155279501 t: 0.3304860591888428\n",
      "Epoch 10: test Loss: 1.7378937005996704 Score: 0.02 t: 0.2979423999786377\n",
      "Epoch 10: test Loss: 0.5105955004692078 Score: 0.3109090909090909 t: 0.30347347259521484\n",
      "Epoch 10: test Loss: 1.9953573942184448 Score: 0.4228571428571429 t: 0.30495786666870117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 11/30 [50:39<1:21:39, 257.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#==##==##==##==##==##==##==#epoch: 10#==##==##==##==##==##==##==#\n",
      "TEST ACC: 0.3256911665542819\n",
      "#==##==##==##==##==##==##==#time: 284.0714313983917#==##==##==##==##==##==##==#\n",
      "\n",
      "Epoch 11: train Loss: 4.89210319519043 Score: 0.1 t: 0.32849860191345215\n",
      "Epoch 11: train Loss: 4.061110973358154 Score: 0.22363636363636366 t: 0.32921838760375977\n",
      "Epoch 11: train Loss: 4.151802062988281 Score: 0.23809523809523808 t: 0.32776355743408203\n",
      "Epoch 11: train Loss: 3.8922600746154785 Score: 0.2387096774193548 t: 0.3278687000274658\n",
      "Epoch 11: train Loss: 3.6495134830474854 Score: 0.23463414634146343 t: 0.331920862197876\n",
      "Epoch 11: train Loss: 3.2331125736236572 Score: 0.23764705882352943 t: 0.3323657512664795\n",
      "Epoch 11: train Loss: 4.094050407409668 Score: 0.23508196721311475 t: 0.32981276512145996\n",
      "Epoch 11: train Loss: 4.37645149230957 Score: 0.23746478873239435 t: 0.3314225673675537\n",
      "Epoch 11: train Loss: 4.183826923370361 Score: 0.23703703703703707 t: 0.32846546173095703\n",
      "Epoch 11: train Loss: 3.64829158782959 Score: 0.23450549450549454 t: 0.3307664394378662\n",
      "Epoch 11: train Loss: 3.407423496246338 Score: 0.23188118811881198 t: 0.3307781219482422\n",
      "Epoch 11: train Loss: 4.16303825378418 Score: 0.2291891891891892 t: 0.329756498336792\n",
      "Epoch 11: train Loss: 3.8741650581359863 Score: 0.22677685950413226 t: 0.329434871673584\n",
      "Epoch 11: train Loss: 3.618121385574341 Score: 0.22595419847328246 t: 0.3350789546966553\n",
      "Epoch 11: train Loss: 4.040646553039551 Score: 0.22411347517730498 t: 0.33333778381347656\n",
      "Epoch 11: train Loss: 3.9049947261810303 Score: 0.22437086092715233 t: 0.32975149154663086\n",
      "Epoch 11: train Loss: 4.153017997741699 Score: 0.224472049689441 t: 0.3322913646697998\n",
      "Epoch 11: test Loss: 1.4932447671890259 Score: 0.26 t: 0.29857778549194336\n",
      "Epoch 11: test Loss: 0.7744073271751404 Score: 0.39818181818181825 t: 0.3022611141204834\n",
      "Epoch 11: test Loss: 1.9913301467895508 Score: 0.4028571428571429 t: 0.30550456047058105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 12/30 [54:50<1:16:44, 255.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#==##==##==##==##==##==##==#epoch: 11#==##==##==##==##==##==##==#\n",
      "TEST ACC: 0.32231962238705325\n",
      "#==##==##==##==##==##==##==#time: 250.98848271369934#==##==##==##==##==##==##==#\n",
      "\n",
      "Epoch 12: train Loss: 3.958484172821045 Score: 0.2 t: 0.3277127742767334\n",
      "Epoch 12: train Loss: 3.5834085941314697 Score: 0.23454545454545456 t: 0.3294503688812256\n",
      "Epoch 12: train Loss: 3.7957804203033447 Score: 0.25142857142857145 t: 0.3303647041320801\n",
      "Epoch 12: train Loss: 4.3805766105651855 Score: 0.2387096774193548 t: 0.3283576965332031\n",
      "Epoch 12: train Loss: 3.849226474761963 Score: 0.24439024390243902 t: 0.3286471366882324\n",
      "Epoch 12: train Loss: 3.8507158756256104 Score: 0.2447058823529412 t: 0.33100223541259766\n",
      "Epoch 12: train Loss: 3.7199268341064453 Score: 0.23901639344262293 t: 0.33179140090942383\n",
      "Epoch 12: train Loss: 3.752009630203247 Score: 0.23746478873239435 t: 0.33176112174987793\n",
      "Epoch 12: train Loss: 4.437532424926758 Score: 0.23185185185185186 t: 0.33189916610717773\n",
      "Epoch 12: train Loss: 4.488086223602295 Score: 0.23252747252747258 t: 0.32612085342407227\n",
      "Epoch 12: train Loss: 3.522379159927368 Score: 0.23108910891089113 t: 0.3314838409423828\n",
      "Epoch 12: train Loss: 4.0122270584106445 Score: 0.22882882882882888 t: 0.3296523094177246\n",
      "Epoch 12: train Loss: 3.74470853805542 Score: 0.2285950413223141 t: 0.3271317481994629\n",
      "Epoch 12: train Loss: 3.722055435180664 Score: 0.2265648854961832 t: 0.33020567893981934\n",
      "Epoch 12: train Loss: 3.9929726123809814 Score: 0.2287943262411348 t: 0.3304011821746826\n",
      "Epoch 12: train Loss: 3.7113327980041504 Score: 0.22807947019867547 t: 0.3269469738006592\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bc5dff263281>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m                                      \u001b[0mepoch\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                                      \u001b[0mtotal_loss_over_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss_over_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                                      scores_over_epochs     = scores_over_epochs)\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     tr_loss, ts_labels, ts_preds = eval_model(data_loader = test_loader,\n",
      "\u001b[0;32m<ipython-input-4-c4f0330a7f96>\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(data_loader, model, criterion, optimizer, batch_size, training, epoch, total_loss_over_epochs, scores_over_epochs)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;31m# extract minibatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Visual-Question-Answering/data_loader.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mquestion_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquestion_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             \u001b[0mv\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m             \u001b[0mq\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mquestion_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0ma\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0manswer_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Visual-Question-Answering/utils.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(path, transform)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"IMG_LOAD_ERR - Image File idx={}: [{}] not found\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2634\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2635\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = EncDec(embed_size, hidden_size, ques_vocab_size, ans_vocab_size, rnn_layers).to(device)\n",
    "model = FuseAttEncDec(embed_size, hidden_size, attention_size, \n",
    "                      ques_vocab_size, ans_vocab_size, num_layers, debug).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.get_parameters(), lr=learning_rate, momentum=momentum)\n",
    "# optimizer = torch.optim.Adam(model.get_parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_loader = dataset.build_data_loader(train=True, args={'batch_size': batch_size})\n",
    "test_loader  = dataset.build_data_loader(test=True, args={'batch_size': batch_size})\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "train_all_loss, train_all_labels, train_all_preds = [], [], []\n",
    "print(\"model built, start training.\")\n",
    "total_loss_over_epochs, scores_over_epochs = plotting.get_empty_stat_over_n_epoch_dictionaries()\n",
    "total_loss_over_epochs2, scores_over_epochs2 = plotting.get_empty_stat_over_n_epoch_dictionaries()\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    t0= time.time()\n",
    "    tr_loss, tr_labels, tr_preds = eval_model(data_loader = train_loader,\n",
    "                                     model       = model,\n",
    "                                     criterion   = criterion,\n",
    "                                     optimizer   = optimizer,\n",
    "                                     batch_size  = batch_size,\n",
    "                                     training    = True,\n",
    "                                     epoch       = epoch,\n",
    "                                     total_loss_over_epochs = total_loss_over_epochs,\n",
    "                                     scores_over_epochs     = scores_over_epochs)\n",
    "    \n",
    "    tr_loss, ts_labels, ts_preds = eval_model(data_loader = test_loader,\n",
    "                                     model       = model,\n",
    "                                     criterion   = criterion,\n",
    "                                     optimizer   = None,\n",
    "                                     batch_size  = batch_size,\n",
    "                                     training    = False,\n",
    "                                     epoch       = epoch,\n",
    "                                     total_loss_over_epochs = total_loss_over_epochs2,\n",
    "                                     scores_over_epochs     = scores_over_epochs2)\n",
    "    \n",
    "    \n",
    "    score = metrics.accuracy_score(ts_preds,ts_labels)\n",
    "#     total_loss_over_epochs['train_loss'].append(tr_loss)\n",
    "#     scores_over_epochs['train_scores'].append(train_scores)\n",
    "    \n",
    "#     if True:# or epoch%1 == 0:\n",
    "    print(\"\\n\"+\"#==#\"*7 + \"epoch: {}\".format(epoch) + \"#==#\"*7)\n",
    "    print('TEST ACC: {}'.format(score))\n",
    "    print(\"#==#\"*7 + \"time: {}\".format(time.time()-t0) + \"#==#\"*7 + \"\\n\")\n",
    "#         print(train_scores)\n",
    "#     plotting.plot_score_over_n_epochs(scores_over_epochs, score_type='precision', fig_size=(8,5))\n",
    "#     plotting.plot_loss_over_n_epochs(total_loss_over_epochs, fig_size=(8, 5), title=\"Loss\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1):\n",
    "    ts_loss, ts_labels, ts_preds = eval_model(data_loader = test_loader,\n",
    "                                     model       = model,\n",
    "                                     criterion   = criterion,\n",
    "                                     optimizer   = None,\n",
    "                                     batch_size  = batch_size,\n",
    "                                     training    = False,\n",
    "                                     epoch       = epoch,\n",
    "                                     total_loss_over_epochs = total_loss_over_epochs2,\n",
    "                                     scores_over_epochs     = scores_over_epochs2)\n",
    "    score = metrics.accuracy_score(ts_preds,ts_labels)\n",
    "    print(\"ACC: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tr_labels[0])\n",
    "print(tr_preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
