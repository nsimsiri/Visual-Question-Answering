{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, json, time\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import plotting\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from utils import imread, img_data_2_mini_batch, imgs2batch\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from attention import Enc, Dec, EncDec\n",
    "from data_loader import VQADataSet\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torchvision import transforms\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/data_2000.pkl\n",
      "reading from ./data/data_2000.pkl\n"
     ]
    }
   ],
   "source": [
    "N = 2000\n",
    "dataset_filename = \"./data/data_{}.pkl\".format(N)\n",
    "dataset = None\n",
    "print(dataset_filename)\n",
    "if (os.path.exists(dataset_filename)):\n",
    "    with open(dataset_filename, 'rb') as handle:\n",
    "        print(\"reading from \" + dataset_filename)\n",
    "        dataset = pickle.load(handle)\n",
    "else:\n",
    "    dataset = VQADataSet(Q=N)\n",
    "    with open(dataset_filename, 'wb') as handle:\n",
    "        print(\"writing to \" + dataset_filename)\n",
    "        pickle.dump(dataset, handle)\n",
    "\n",
    "assert(dataset is not None)\n",
    "def debug(v,q,a):\n",
    "    print('\\nV: {}\\nQ: {}\\nA: {}'.format(v.shape, q.shape, a.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size        = 300\n",
    "hidden_size       = 1024\n",
    "batch_size        = 32\n",
    "ques_vocab_size   = len(dataset.vocab['question'])\n",
    "c                 = len(dataset.vocab['answer'])\n",
    "num_layers        = 1\n",
    "n_epochs          = 20\n",
    "learning_rate     = 0.01\n",
    "momentum          = 0.98\n",
    "attention_size    = 512\n",
    "debug             = False\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = EncDec(embed_size, hidden_size, attention_size, ques_vocab_size, c, num_layers, debug).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1282"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(data_loader, model, criterion, optimizer, batch_size, training=False,\n",
    "              total_loss_over_epochs=[], scores_over_epochs=[]):\n",
    "    running_loss = 0.\n",
    "    final_labels, final_preds = [], []\n",
    "    if data_loader is None:\n",
    "        return\n",
    "    \n",
    "    if training:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    \n",
    "    for i, minibatch in enumerate(data_loader):\n",
    "        # extract minibatch\n",
    "        t0 = time.time()\n",
    "        idxs, v, q, a, q_len = minibatch\n",
    "        \n",
    "        # convert torch's DataLoader output to proper format.\n",
    "        # torch gives a List[Tensor_1, ... ] where tensor has been transposed. \n",
    "        # batchify transposes back.`\n",
    "        v = v.to(device)\n",
    "        q = VQADataSet.batchify_questions(q).to(device)\n",
    "        a = a.to(device)\n",
    "                \n",
    "\n",
    "\n",
    "        logits = model(v, q, q_len)\n",
    "        \n",
    "        loss = F.nll_loss(logits, a)\n",
    "    \n",
    "        print(loss.item())\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 32 shuffle: True\n",
      "batch_size: 32 shuffle: False\n",
      "7.1504316329956055\n",
      "7.165352821350098\n",
      "7.135380268096924\n",
      "7.083408832550049\n",
      "7.1949944496154785\n",
      "7.144080638885498\n",
      "7.249777317047119\n",
      "7.112883567810059\n",
      "7.164816379547119\n",
      "7.1680588722229\n",
      "7.194150447845459\n",
      "7.140851020812988\n",
      "7.109874248504639\n",
      "7.156062602996826\n",
      "7.206156253814697\n",
      "7.152928829193115\n",
      "7.139535903930664\n",
      "7.182536602020264\n",
      "7.058390140533447\n",
      "7.139483451843262\n",
      "7.156867027282715\n",
      "7.161696434020996\n",
      "7.250360488891602\n",
      "7.154489040374756\n",
      "7.185787677764893\n",
      "7.0475382804870605\n",
      "7.06500244140625\n",
      "7.276723861694336\n",
      "7.217381954193115\n",
      "7.216460704803467\n",
      "7.251987934112549\n",
      "7.2334160804748535\n",
      "7.085299968719482\n",
      "7.169120788574219\n",
      "7.238846778869629\n",
      "7.13566255569458\n",
      "7.288168430328369\n",
      "7.174676418304443\n",
      "7.103623867034912\n",
      "7.223609447479248\n",
      "7.115533351898193\n",
      "7.102667808532715\n",
      "7.230281352996826\n",
      "7.127016544342041\n",
      "7.176954746246338\n",
      "7.182290077209473\n",
      "7.189122200012207\n",
      "7.247584342956543\n",
      "7.126515865325928\n",
      "7.12155294418335\n",
      "7.224917411804199\n",
      "7.234164237976074\n",
      "7.108067989349365\n",
      "7.230669021606445\n",
      "7.182584762573242\n",
      "7.162582874298096\n",
      "7.093473434448242\n",
      "7.102077484130859\n",
      "7.102218151092529\n",
      "7.276350975036621\n",
      "7.179914474487305\n",
      "7.17828369140625\n",
      "7.112520217895508\n",
      "7.153360843658447\n",
      "7.177608489990234\n",
      "7.1927056312561035\n",
      "7.2020087242126465\n",
      "7.187187671661377\n",
      "7.117471694946289\n",
      "7.170687198638916\n",
      "7.198516845703125\n",
      "7.166921615600586\n",
      "7.155912399291992\n",
      "7.199650764465332\n",
      "7.183455467224121\n",
      "7.20878791809082\n",
      "7.1405487060546875\n",
      "7.175492286682129\n",
      "7.142816543579102\n",
      "7.248860836029053\n",
      "7.174767017364502\n",
      "7.183611869812012\n",
      "7.221878528594971\n",
      "7.165085792541504\n",
      "7.1025214195251465\n",
      "7.090445041656494\n",
      "7.171522617340088\n",
      "7.174769878387451\n",
      "7.125525951385498\n",
      "7.182534694671631\n",
      "7.1493306159973145\n",
      "7.165603160858154\n",
      "7.1979217529296875\n",
      "7.176799297332764\n",
      "7.169726848602295\n",
      "7.220559120178223\n",
      "7.15603494644165\n",
      "7.16154670715332\n",
      "7.228525638580322\n",
      "7.210602283477783\n",
      "7.2128825187683105\n",
      "7.228638172149658\n",
      "7.172433853149414\n",
      "7.135808944702148\n",
      "7.100709438323975\n",
      "7.1700849533081055\n",
      "7.19094705581665\n",
      "7.148617744445801\n",
      "7.225433826446533\n",
      "7.126872539520264\n",
      "7.093559265136719\n",
      "7.164357662200928\n",
      "7.250148296356201\n",
      "7.153992176055908\n",
      "7.24951696395874\n",
      "7.112902641296387\n",
      "7.120967864990234\n",
      "7.1585187911987305\n",
      "7.155581474304199\n",
      "7.225503444671631\n",
      "7.151322841644287\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6800f6e32bea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                      \u001b[0mtraining\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                      \u001b[0mtotal_loss_over_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss_over_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                                      scores_over_epochs     = scores_over_epochs)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#     train_scores = metrics.precision_recall_fscore_support(tr_labels,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader = dataset.build_data_loader(train=True, args={'batch_size': batch_size})\n",
    "test_loader  = dataset.build_data_loader(test=True, args={'batch_size': batch_size})\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "train_all_loss, train_all_labels, train_all_preds = [], [], []\n",
    "\n",
    "total_loss_over_epochs, scores_over_epochs = plotting.get_empty_stat_over_n_epoch_dictionaries()\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    t0= time.time()\n",
    "    tr_loss, tr_labels, tr_preds = eval_model(data_loader = train_loader,\n",
    "                                     model       = model,\n",
    "                                     criterion   = criterion,\n",
    "                                     optimizer   = optimizer,\n",
    "                                     batch_size  = batch_size,\n",
    "                                     training    = True,\n",
    "                                     total_loss_over_epochs = total_loss_over_epochs,\n",
    "                                     scores_over_epochs     = scores_over_epochs)\n",
    "    \n",
    "#     train_scores = metrics.precision_recall_fscore_support(tr_labels,\n",
    "#                                                            tr_preds,\n",
    "#                                                            average='weighted')\n",
    "    \n",
    "#     total_loss_over_epochs['train_loss'].append(tr_loss)\n",
    "#     scores_over_epochs['train_scores'].append(train_scores)\n",
    "    \n",
    "#     if True:# or epoch%1 == 0:\n",
    "#         print(\"#==#\"*5 + \"epoch: {}\".format(epoch) + \"#==#\"*5)\n",
    "#         print(\"time: {}\".format(time.time()-t0))\n",
    "#         print(train_scores)\n",
    "#     plotting.plot_score_over_n_epochs(scores_over_epochs, score_type='precision', fig_size=(8,5))\n",
    "#     plotting.plot_loss_over_n_epochs(total_loss_over_epochs, fig_size=(8, 5), title=\"Loss\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(tr_labels))\n",
    "# print(type(tr_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tr_labels[0])\n",
    "# print(tr_preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
