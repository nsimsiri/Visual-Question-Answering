{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.utils.rnn as rnn_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 4., 6.],\n",
      "        [2., 5., 0.],\n",
      "        [3., 0., 0.]])\n",
      "PackedSequence(data=tensor([1., 2., 3., 4., 5., 6.]), batch_sizes=tensor([3, 2, 1]))\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 0.],\n",
      "        [6., 0., 0.]])\n",
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([1, 2, 3])\n",
    "b = torch.Tensor([4, 5, 0])\n",
    "c = torch.Tensor([6, 0, 0])\n",
    "d = torch.stack([a, b, c],1)\n",
    "print d\n",
    "pack = rnn_utils.pack_padded_sequence(d, torch.Tensor([3,2,1]).long(), batch_first=True)\n",
    "print pack\n",
    "\n",
    "unpack, lengths = rnn_utils.pad_packed_sequence(pack)\n",
    "\n",
    "print unpack\n",
    "print unpack[0]\n",
    "# out = rnn_utils.pack_padded_sequence([a, b, c], batch_first=True)\n",
    "# print out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "va, vlen\n",
      "(tensor([[1, 2, 3],\n",
      "        [7, 8, 9],\n",
      "        [4, 5, 0],\n",
      "        [6, 0, 0]]), tensor([3, 3, 2, 1]))\n",
      "\n",
      "lstm------\n",
      "PackedSequence(data=tensor([[-0.0677,  0.1141, -0.0320, -0.0092,  0.0023, -0.0765, -0.0856,  0.0674,\n",
      "         -0.0150,  0.0464],\n",
      "        [-0.0734,  0.1129, -0.0267, -0.0052, -0.0089, -0.0771, -0.0820,  0.0527,\n",
      "         -0.0162,  0.0301],\n",
      "        [-0.0602,  0.1219, -0.0399,  0.0327, -0.0093, -0.0755, -0.0957,  0.0645,\n",
      "         -0.0271,  0.0274],\n",
      "        [-0.0694,  0.1156, -0.0351,  0.0109, -0.0053, -0.0845, -0.0892,  0.0660,\n",
      "         -0.0266,  0.0343],\n",
      "        [-0.0704,  0.1836, -0.0327, -0.0002,  0.0007, -0.1083, -0.1414,  0.1291,\n",
      "         -0.0254,  0.0696],\n",
      "        [-0.0936,  0.1799, -0.0522, -0.0078, -0.0086, -0.1134, -0.1273,  0.1132,\n",
      "         -0.0249,  0.0555],\n",
      "        [-0.0835,  0.1808, -0.0400,  0.0294, -0.0118, -0.1048, -0.1439,  0.1123,\n",
      "         -0.0270,  0.0431],\n",
      "        [-0.0719,  0.2156, -0.0238,  0.0410, -0.0077, -0.1229, -0.1706,  0.1560,\n",
      "         -0.0390,  0.0695],\n",
      "        [-0.0982,  0.2028, -0.0817, -0.0430, -0.0264, -0.1199, -0.1447,  0.1257,\n",
      "         -0.0061,  0.0718]], grad_fn=<CatBackward>), batch_sizes=tensor([4, 3, 2], grad_fn=<PackPaddedBackward>))\n",
      "\n",
      "after padded:\n",
      "torch.Size([4, 3, 10])\n",
      "tensor([[[-0.0677,  0.1141, -0.0320, -0.0092,  0.0023, -0.0765, -0.0856,\n",
      "           0.0674, -0.0150,  0.0464],\n",
      "         [-0.0704,  0.1836, -0.0327, -0.0002,  0.0007, -0.1083, -0.1414,\n",
      "           0.1291, -0.0254,  0.0696],\n",
      "         [-0.0719,  0.2156, -0.0238,  0.0410, -0.0077, -0.1229, -0.1706,\n",
      "           0.1560, -0.0390,  0.0695]],\n",
      "\n",
      "        [[-0.0734,  0.1129, -0.0267, -0.0052, -0.0089, -0.0771, -0.0820,\n",
      "           0.0527, -0.0162,  0.0301],\n",
      "         [-0.0936,  0.1799, -0.0522, -0.0078, -0.0086, -0.1134, -0.1273,\n",
      "           0.1132, -0.0249,  0.0555],\n",
      "         [-0.0982,  0.2028, -0.0817, -0.0430, -0.0264, -0.1199, -0.1447,\n",
      "           0.1257, -0.0061,  0.0718]],\n",
      "\n",
      "        [[-0.0602,  0.1219, -0.0399,  0.0327, -0.0093, -0.0755, -0.0957,\n",
      "           0.0645, -0.0271,  0.0274],\n",
      "         [-0.0835,  0.1808, -0.0400,  0.0294, -0.0118, -0.1048, -0.1439,\n",
      "           0.1123, -0.0270,  0.0431],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0694,  0.1156, -0.0351,  0.0109, -0.0053, -0.0845, -0.0892,\n",
      "           0.0660, -0.0266,  0.0343],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "           0.0000,  0.0000,  0.0000]]], grad_fn=<TransposeBackward0>)\n",
      "\n",
      "hn\n",
      "tensor([[-0.0719,  0.2156, -0.0238,  0.0410, -0.0077, -0.1229, -0.1706,  0.1560,\n",
      "         -0.0390,  0.0695],\n",
      "        [-0.0982,  0.2028, -0.0817, -0.0430, -0.0264, -0.1199, -0.1447,  0.1257,\n",
      "         -0.0061,  0.0718],\n",
      "        [-0.0835,  0.1808, -0.0400,  0.0294, -0.0118, -0.1048, -0.1439,  0.1123,\n",
      "         -0.0270,  0.0431],\n",
      "        [-0.0694,  0.1156, -0.0351,  0.0109, -0.0053, -0.0845, -0.0892,  0.0660,\n",
      "         -0.0266,  0.0343]], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "import numpy as np\n",
    "\n",
    "max_seq_len = 3\n",
    "batch_size = 4\n",
    "layer_num = 2\n",
    "\n",
    "input_size = 10 # 0 - 9\n",
    "emb_size = 8\n",
    "hidden_size = 10\n",
    "\n",
    "# test data:\n",
    "a = [[1,2,3], [4,5,0], [6,0,0], [7,8,9]]\n",
    "lens = [3,2,1,3]\n",
    "\n",
    "# sort the input batch data by reversed actual length for pad_pack operation\n",
    "pairs = sorted( zip(a, lens), key=lambda p: p[1], reverse=True)\n",
    "(a, lens) = zip(*pairs)\n",
    "\n",
    "# actual length\n",
    "lens = np.array(lens)\n",
    "# lens = torch.LongTensor(lens)\n",
    "\n",
    "va = Variable(torch.LongTensor(a))\n",
    "vlens = Variable(torch.LongTensor(lens))\n",
    "print 'va, vlen'\n",
    "print(va, vlens)\n",
    "print\n",
    "\n",
    "embedding = nn.Embedding(input_size, emb_size)\n",
    "gru = nn.LSTM(emb_size, hidden_size, layer_num, batch_first=True)\n",
    "\n",
    "# print 'va.size'\n",
    "# print va.size()\n",
    "# print \n",
    "\n",
    "# print 'vlens'\n",
    "# print vlens\n",
    "# print \n",
    "\n",
    "inputs = va\n",
    "# inputs = va.transpose(0, 1); \n",
    "# print(\"inputs size: \", inputs.size()) # max_seq_len * batch_size\n",
    "\n",
    "inputs = embedding(inputs); \n",
    "# print(\"embedded size: \", inputs.size()) # max_seq_len * batch_size * emb_size\n",
    "\n",
    "packed = torch.nn.utils.rnn.pack_padded_sequence(inputs, lens, batch_first=True)\n",
    "\n",
    "# print 'packed', \n",
    "# print packed\n",
    "# print \n",
    "\n",
    "# h0 = Variable(torch.randn(layer_num, 4, 10))\n",
    "outputs, (hn, cn) = gru(packed)\n",
    "\n",
    "print 'lstm------'\n",
    "print outputs\n",
    "print\n",
    "tmp = torch.nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
    "\n",
    "outputs, output_lengths = tmp\n",
    "\n",
    "print\"after padded:\"\n",
    "print outputs.size()\n",
    "print outputs\n",
    "print\n",
    "\n",
    "print \"hn\"\n",
    "print hn[-1]\n",
    "# print(\"outputs.size: \", outputs.size())\n",
    "# print(\"hn size: \", hn.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 1, 0])\n",
      "tensor([[2, 2, 1, 0]])\n",
      "tensor([[[2],\n",
      "         [2],\n",
      "         [1],\n",
      "         [0]]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (3) must match the existing size (4) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-9067891c9e05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmasks\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# print masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# output = outputs.gather(0, masks)[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (3) must match the existing size (4) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "masks = (vlens-1)\n",
    "print masks\n",
    "masks = masks.unsqueeze(0)\n",
    "print masks\n",
    "masks = masks.unsqueeze(2)\n",
    "print masks\n",
    "masks= masks.expand(max_seq_len, outputs.size(1), outputs.size(2))\n",
    "# print masks\n",
    "# output = outputs.gather(0, masks)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'Variable'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-fa84614d9b0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'Variable'"
     ]
    }
   ],
   "source": [
    "nn.Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
