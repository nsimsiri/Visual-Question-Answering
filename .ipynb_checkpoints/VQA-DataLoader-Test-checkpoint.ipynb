{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pickle\n",
    "import h5py\n",
    "import re\n",
    "from utils import img_data_2_mini_batch, imgs2batch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as Data\n",
    "from torchvision import transforms\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import functools as ft\n",
    "\n",
    "%matplotlib inline\n",
    "import torch.nn.functional as F\n",
    "import sys, os\n",
    "from IPython.display import display, HTML\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import VQADataSet\n",
    "pp = lambda parsed: print(json.dumps(parsed, indent=4, sort_keys=True))\n",
    "N = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_2000.pkl\n",
      "reading from ./data_2000.pkl\n"
     ]
    }
   ],
   "source": [
    "dataset_filename = \"./data_{}.pkl\".format(N)\n",
    "dataset = None\n",
    "print(dataset_filename)\n",
    "if (os.path.exists(dataset_filename)):\n",
    "    with open(dataset_filename, 'rb') as handle:\n",
    "        print(\"reading from \" + dataset_filename)\n",
    "        dataset = pickle.load(handle)\n",
    "else:\n",
    "    dataset = VQADataSet(Q=N)\n",
    "    with open(dataset_filename, 'wb') as handle:\n",
    "        print(\"writing to \" + dataset_filename)\n",
    "        pickle.dump(dataset, handle)\n",
    "\n",
    "assert(dataset is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507\n",
      "3850\n"
     ]
    }
   ],
   "source": [
    "# print(len(dataset.anns))\n",
    "N_sample = 4\n",
    "q_keys = list(dataset.question_maps.keys())\n",
    "# for q_key in q_keys[:N_sample]:\n",
    "#     pp(dataset.question_maps[q_key])\n",
    "# pp(dataset.answer_maps[:N_sample])\n",
    "print(len(dataset.splits['test']))\n",
    "print(len(dataset.splits['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_distribution(dataset):\n",
    "    train = dataset.splits['train']\n",
    "    test = dataset.splits['test']\n",
    "    print('train: {} test:{} percent: {} total: {}'.format(\n",
    "        len(train),\n",
    "        len(test),\n",
    "        len(train)/len(train+test),\n",
    "        len(train) + len(test),\n",
    "    ))\n",
    "    def split_to_freq(split, T=None):\n",
    "        anns = [dataset.answer_maps[i] for i in split]\n",
    "        _cntr = defaultdict(int)\n",
    "        for ann in anns:\n",
    "            _cntr[ann['answer']]+=1\n",
    "        tmp = sorted(_cntr.items(), key=lambda kv: kv[1], reverse=True)[:T]\n",
    "        print(len(tmp))\n",
    "        return [x[1] for x in tmp]\n",
    "\n",
    "    def plot_freq(title, Y):\n",
    "        X = range(len(Y))\n",
    "        plt.bar(X, Y)\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "    train_freq = split_to_freq(train, T=50)#len(train))\n",
    "    test_freq = split_to_freq(test, T=50)#(train))\n",
    "    plot_freq(\"train frequency\", train_freq)\n",
    "    plot_freq(\"test frequency\", test_freq)\n",
    "    print('1', len(train_freq))\n",
    "\n",
    "# plot_distribution(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 5 shuffle: True\n",
      "\tcheck : <start> is the chandelier hung low ? <end> <pad> <pad> <pad> <pad>\n",
      "\tanswer :['<start>', 'is', 'the', 'chandelier', 'hung', 'low', '?', '<end>']\n",
      "\tcheck: yes\n",
      "\tanswer :yes\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "train_loader = dataset.build_data_loader(train=True, args={'batch_size': 5})\n",
    "# print(len(train_loader))\n",
    "for minibatch in train_loader:\n",
    "    idxs, v,q,a,q_len = minibatch\n",
    "    q = VQADataSet.batchify_questions(q)\n",
    "    batch_size = len(q_len)\n",
    "    for i in range(batch_size):\n",
    "        idx_i = idxs[i]\n",
    "        q_i = q[i]\n",
    "        a_i = a[i]\n",
    "        q_len_i = q_len[i]\n",
    "        qj, aj = dataset.get(idx_i, 'train')\n",
    "        print(\"\\tcheck: \" + dataset.decode_question(q_i.tolist()))\n",
    "        print(\"\\tanswer:\" + str(qj['tokens']))\n",
    "        print(\"\\tcheck: \" + str(dataset.decode_answer(a_i)))\n",
    "\n",
    "        print(\"\\tanswer: \" + aj['answer'])\n",
    "#         pp(aj['answer'])\n",
    "        \n",
    "        break\n",
    "        \n",
    "# #     print(v.shape)\n",
    "# #     print(\"\\n\")\n",
    "# #     print(q)\n",
    "# #     print(\"\\n\")\n",
    "# #     print(a)\n",
    "# #     print('n')\n",
    "# #     print(q_len)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= 'data/val2014/COCO_val2014_000000262274.jpg'\n",
    "\n",
    "print(os.path.exists(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://arxiv.org/pdf/1803.07724.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pp(dataset.answer_maps)\n",
    "# from random import shuffle\n",
    "# from collections import defaultdict\n",
    "# cntr = defaultdict(int)\n",
    "# dist = defaultdict(list)\n",
    "# for i, ann in enumerate(dataset.answer_maps):\n",
    "#     ans = ann['answer']\n",
    "#     cntr[ans]+=1\n",
    "#     dist[ans].append(i)\n",
    "#     split = {'train': [], 'test': []}\n",
    "#     z_cnt = 0\n",
    "#     for ans, idxes in dist.items():\n",
    "#         shuffle(idxes)\n",
    "#         c = int(len(idxes)*0.20)\n",
    "#         split['train'] += idxes[c:]\n",
    "#         split['test'] += idxes[:c]\n",
    "#     split['test'].sort()\n",
    "#     print(split['test'][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.itoq[0])\n",
    "print(dataset.itoq[1])\n",
    "print(dataset.itoq[2])\n",
    "print(dataset.itoq[3])\n",
    "\n",
    "print(dataset.qtoi['<pad>'])\n",
    "print(dataset.qtoi['<start>'])\n",
    "print(dataset.qtoi['<end>'])\n",
    "print(dataset.qtoi['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3_6",
   "language": "python",
   "name": "python3_6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
