{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bokeh'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8344a8fb3e2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mplotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code/ml/nlp/vqa/plotting.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mLOSS_OVER_N_EPOCHS_DICT_KEYS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"train_loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bokeh'"
     ]
    }
   ],
   "source": [
    "import sys, os, re, json, time\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import plotting\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from utils import imread, img_data_2_mini_batch, imgs2batch\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from naive import Enc, Dec, EncDec\n",
    "from data_loader import VQADataSet\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torchvision import transforms\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/data_2000.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:05<00:00, 375.14it/s]\n",
      "100%|██████████| 1979/1979 [00:00<00:00, 691941.28it/s]\n",
      "100%|██████████| 1979/1979 [00:00<00:00, 7857.37it/s]\n",
      "100%|██████████| 1979/1979 [00:00<00:00, 244860.55it/s]\n",
      "100%|██████████| 1979/1979 [00:00<00:00, 321489.12it/s]\n",
      "100%|██████████| 509/509 [00:00<00:00, 53819.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VQADataSet init time: 11.126109838485718\n",
      "writing to ./data/data_2000.pkl\n"
     ]
    }
   ],
   "source": [
    "N = 2000\n",
    "dataset_filename = \"./data/data_{}.pkl\".format(N)\n",
    "dataset = None\n",
    "print(dataset_filename)\n",
    "if (os.path.exists(dataset_filename)):\n",
    "    with open(dataset_filename, 'rb') as handle:\n",
    "        print(\"reading from \" + dataset_filename)\n",
    "        dataset = pickle.load(handle)\n",
    "else:\n",
    "    dataset = VQADataSet(Q=N)\n",
    "    with open(dataset_filename, 'wb') as handle:\n",
    "        print(\"writing to \" + dataset_filename)\n",
    "        pickle.dump(dataset, handle)\n",
    "\n",
    "assert(dataset is not None)\n",
    "def debug(v,q,a):\n",
    "    print('\\nV: {}\\nQ: {}\\nA: {}'.format(v.shape, q.shape, a.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1469 509\n"
     ]
    }
   ],
   "source": [
    "embed_size        = 128\n",
    "hidden_size       = 128\n",
    "batch_size        = 32\n",
    "ques_vocab_size   = len(dataset.vocab['question'])\n",
    "ans_vocab_size    = len(dataset.vocab['answer'])\n",
    "rnn_layers        = 1\n",
    "n_epochs          = 25\n",
    "learning_rate     = 0.01\n",
    "momentum          = 0.98\n",
    "\n",
    "print(ques_vocab_size, ans_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(data_loader, model, criterion, optimizer, batch_size, training=False,\n",
    "              total_loss_over_epochs=[], scores_over_epochs=[]):\n",
    "    running_loss = 0.\n",
    "    final_labels, final_preds = [], []\n",
    "    if data_loader is None:\n",
    "        return\n",
    "    \n",
    "    if training:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    \n",
    "    for i, minibatch in enumerate(data_loader):\n",
    "        # extract minibatch\n",
    "        t0 = time.time()\n",
    "        idxs, v, q, a, q_len = minibatch\n",
    "        \n",
    "        # convert torch's DataLoader output to proper format.\n",
    "        # torch gives a List[Tensor_1, ... ] where tensor has been transposed. \n",
    "        # batchify transposes back.`\n",
    "        v = v.to(device)\n",
    "        q = VQADataSet.batchify_questions(q).to(device)\n",
    "        a = a.to(device)\n",
    "\n",
    "        logits = model(v, q, q_len)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "#         loss = criterion(logits, a)\n",
    "        loss = F.nll_loss(logits, a)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        score = metrics.precision_recall_fscore_support(preds.tolist(),\n",
    "                                                        a.tolist(),\n",
    "                                                        average='weighted')\n",
    "        \n",
    "        total_loss_over_epochs['train_loss'].append(loss)\n",
    "        scores_over_epochs['train_scores'].append(score)\n",
    "        \n",
    "        if training and optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        final_labels += a.tolist()\n",
    "        final_preds  += preds.tolist()\n",
    "        if True:#(i%20==0):\n",
    "#             plotting.plot_score_over_n_epochs(scores_over_epochs, score_type='precision', fig_size=(7,3))\n",
    "#             plotting.plot_loss_over_n_epochs(total_loss_over_epochs, fig_size=(7, 3), title=\"Loss\")\n",
    "            print(\"Loss: {} - score: {} - t: {}\".format(loss, score, time.time()-t0))\n",
    "            \n",
    "    return running_loss, final_labels, final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = EncDec(embed_size, hidden_size, ques_vocab_size, ans_vocab_size, rnn_layers).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.get_parameters(), lr=learning_rate, momentum=momentum)\n",
    "optimizer = torch.optim.Adam(model.get_parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 32 shuffle: True\n",
      "batch_size: 32 shuffle: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nsimsiri/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nsimsiri/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 6.2394843101501465 - score: (0.0, 0.0, 0.0, None) - t: 0.28528499603271484\n",
      "Loss: 6.18806266784668 - score: (0.0, 0.0, 0.0, None) - t: 0.2519233226776123\n",
      "Loss: 6.1274237632751465 - score: (0.125, 0.0625, 0.08333333333333333, None) - t: 0.24086761474609375\n",
      "Loss: 5.885769844055176 - score: (0.4618055555555556, 0.21875, 0.296875, None) - t: 0.24924707412719727\n",
      "Loss: 5.541611194610596 - score: (0.8616071428571429, 0.25, 0.3211245519713262, None) - t: 0.24949860572814941\n",
      "Loss: 5.2758073806762695 - score: (0.875, 0.09375, 0.16935483870967738, None) - t: 0.24796700477600098\n",
      "Loss: 4.5459160804748535 - score: (0.37734375, 0.15625, 0.21389751552795033, None) - t: 0.24123477935791016\n",
      "Loss: 5.480690956115723 - score: (1.0, 0.09375, 0.17142857142857143, None) - t: 0.2491469383239746\n",
      "Loss: 5.495992660522461 - score: (1.0, 0.15625, 0.2702702702702703, None) - t: 0.2487189769744873\n",
      "Loss: 4.906850337982178 - score: (0.90625, 0.1875, 0.3107142857142857, None) - t: 0.2502307891845703\n",
      "Loss: 4.616382122039795 - score: (0.49479166666666663, 0.21875, 0.3032635467980296, None) - t: 0.2480297088623047\n",
      "Loss: 5.128124713897705 - score: (0.42500000000000004, 0.125, 0.19318181818181815, None) - t: 0.25067138671875\n",
      "Loss: 4.614511966705322 - score: (0.58828125, 0.25, 0.35083912037037035, None) - t: 0.252185583114624\n",
      "Loss: 3.8417673110961914 - score: (0.603125, 0.3125, 0.4115032327586207, None) - t: 0.25258731842041016\n",
      "Loss: 4.723513603210449 - score: (0.6927083333333334, 0.25, 0.36177884615384615, None) - t: 0.24820470809936523\n",
      "Loss: 4.271255970001221 - score: (0.65625, 0.1875, 0.2916666666666667, None) - t: 0.2525148391723633\n",
      "Loss: 4.991973400115967 - score: (0.6875, 0.09375, 0.165, None) - t: 0.2448892593383789\n",
      "Loss: 4.140108585357666 - score: (0.71875, 0.25, 0.3709677419354839, None) - t: 0.25045251846313477\n",
      "Loss: 4.632561206817627 - score: (0.4375, 0.1875, 0.2625, None) - t: 0.24966049194335938\n",
      "Loss: 4.027975559234619 - score: (0.607638888888889, 0.3125, 0.40164576802507845, None) - t: 0.2415299415588379\n",
      "Loss: 4.621453762054443 - score: (0.5625, 0.21875, 0.31500000000000006, None) - t: 0.25050878524780273\n",
      "Loss: 4.548917293548584 - score: (0.425, 0.15625, 0.21703296703296704, None) - t: 0.24965500831604004\n",
      "Loss: 3.8281843662261963 - score: (0.4125, 0.25, 0.28968253968253965, None) - t: 0.24935030937194824\n",
      "Loss: 4.34749174118042 - score: (0.25, 0.125, 0.16666666666666666, None) - t: 0.24851036071777344\n",
      "Loss: 4.054849147796631 - score: (0.5104166666666667, 0.1875, 0.2583333333333333, None) - t: 0.24189233779907227\n",
      "Loss: 4.11768102645874 - score: (0.703125, 0.21875, 0.3158653846153846, None) - t: 0.24176669120788574\n",
      "Loss: 4.218269348144531 - score: (0.78125, 0.3125, 0.44375, None) - t: 0.24264264106750488\n",
      "Loss: 3.9214494228363037 - score: (0.65625, 0.21875, 0.328125, None) - t: 0.2480916976928711\n",
      "Loss: 4.39735221862793 - score: (0.59375, 0.1875, 0.2754934210526316, None) - t: 0.24876070022583008\n",
      "Loss: 3.887604236602783 - score: (0.5078125, 0.375, 0.42801724137931035, None) - t: 0.2465531826019287\n",
      "Loss: 3.0847983360290527 - score: (0.6875, 0.34375, 0.4583333333333333, None) - t: 0.250821590423584\n",
      "Loss: 4.894207954406738 - score: (0.6041666666666666, 0.09375, 0.15975935828877005, None) - t: 0.24609613418579102\n",
      "Loss: 4.2878546714782715 - score: (0.5848214285714286, 0.1875, 0.27060688405797106, None) - t: 0.24226713180541992\n",
      "Loss: 4.649960994720459 - score: (0.6197916666666667, 0.21875, 0.3080615942028986, None) - t: 0.24268722534179688\n",
      "Loss: 3.313793420791626 - score: (0.41220238095238093, 0.25, 0.2899259868421053, None) - t: 0.24835824966430664\n",
      "Loss: 4.219208240509033 - score: (0.234375, 0.1875, 0.2083333333333333, None) - t: 0.24676251411437988\n",
      "Loss: 4.475785732269287 - score: (0.3515625, 0.125, 0.18437499999999998, None) - t: 0.2474377155303955\n",
      "Loss: 4.354403972625732 - score: (0.4270833333333333, 0.25, 0.30833333333333335, None) - t: 0.25238656997680664\n",
      "Loss: 4.226664066314697 - score: (0.375, 0.1875, 0.25, None) - t: 0.2470839023590088\n",
      "Loss: 4.037045478820801 - score: (0.4375, 0.125, 0.19444444444444445, None) - t: 0.24695134162902832\n",
      "Loss: 4.187259197235107 - score: (0.71875, 0.3125, 0.4116596638655462, None) - t: 0.24768567085266113\n",
      "Loss: 4.516567707061768 - score: (0.25, 0.0625, 0.0859375, None) - t: 0.24241113662719727\n",
      "Loss: 3.456552505493164 - score: (0.3472222222222222, 0.25, 0.27380952380952384, None) - t: 0.2488551139831543\n",
      "Loss: 5.039664268493652 - score: (0.43125, 0.15625, 0.22708333333333333, None) - t: 0.24255585670471191\n",
      "Loss: 3.656925916671753 - score: (0.6302083333333334, 0.28125, 0.3593073593073593, None) - t: 0.24591398239135742\n",
      "Loss: 4.643548011779785 - score: (0.2890625, 0.125, 0.16874999999999998, None) - t: 0.24248957633972168\n",
      "Loss: 3.5287132263183594 - score: (0.5625, 0.25, 0.3416666666666666, None) - t: 0.24157047271728516\n",
      "Loss: 3.6337270736694336 - score: (0.4375, 0.15625, 0.23026315789473684, None) - t: 0.2426924705505371\n",
      "Loss: 3.83007550239563 - score: (0.34375, 0.1875, 0.24264705882352938, None) - t: 0.24209833145141602\n",
      "Loss: 3.2945220470428467 - score: (0.59375, 0.21875, 0.31954887218045114, None) - t: 0.24896860122680664\n",
      "Loss: 3.818901300430298 - score: (0.4765625, 0.21875, 0.27401315789473685, None) - t: 0.24094867706298828\n",
      "Loss: 4.287169456481934 - score: (0.375, 0.1875, 0.25, None) - t: 0.2423999309539795\n",
      "Loss: 3.3408043384552 - score: (0.3645833333333333, 0.21875, 0.2606359649122807, None) - t: 0.2506847381591797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 1/25 [00:46<18:27, 46.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 5.092282295227051 - score: (0.6896551724137931, 0.20689655172413793, 0.3022546419098143, None) - t: 0.2135171890258789\n",
      "Loss: 3.427579402923584 - score: (0.65625, 0.25, 0.3618551587301587, None) - t: 0.2486882209777832\n",
      "Loss: 4.327885150909424 - score: (0.47395833333333337, 0.21875, 0.2855392156862745, None) - t: 0.2441718578338623\n",
      "Loss: 3.7157018184661865 - score: (0.5625, 0.15625, 0.2269345238095238, None) - t: 0.25115060806274414\n",
      "Loss: 3.429935932159424 - score: (0.625, 0.3125, 0.4063988095238095, None) - t: 0.24688172340393066\n",
      "Loss: 2.9368233680725098 - score: (0.459375, 0.28125, 0.2927389705882353, None) - t: 0.25553154945373535\n",
      "Loss: 3.8653032779693604 - score: (0.4166666666666667, 0.21875, 0.2765625, None) - t: 0.2543144226074219\n",
      "Loss: 3.403931140899658 - score: (0.5625, 0.1875, 0.28125, None) - t: 0.24820590019226074\n",
      "Loss: 3.388094186782837 - score: (0.484375, 0.3125, 0.3791666666666667, None) - t: 0.24448823928833008\n",
      "Loss: 4.332608699798584 - score: (0.5625, 0.15625, 0.23214285714285715, None) - t: 0.2494068145751953\n",
      "Loss: 3.996006965637207 - score: (0.2552083333333333, 0.1875, 0.19166666666666668, None) - t: 0.24431514739990234\n",
      "Loss: 2.770784378051758 - score: (0.75, 0.40625, 0.5267857142857143, None) - t: 0.2486412525177002\n",
      "Loss: 3.6848111152648926 - score: (0.4375, 0.15625, 0.23026315789473684, None) - t: 0.24486947059631348\n",
      "Loss: 3.847179651260376 - score: (0.4375, 0.1875, 0.2583333333333333, None) - t: 0.24441957473754883\n",
      "Loss: 3.9087741374969482 - score: (0.546875, 0.1875, 0.275, None) - t: 0.24988007545471191\n",
      "Loss: 2.7642178535461426 - score: (0.59375, 0.1875, 0.284375, None) - t: 0.2481846809387207\n",
      "Loss: 3.663792610168457 - score: (0.828125, 0.25, 0.34078054298642535, None) - t: 0.24709272384643555\n",
      "Loss: 3.8398597240448 - score: (0.34375, 0.1875, 0.24264705882352938, None) - t: 0.249924898147583\n",
      "Loss: 3.7004995346069336 - score: (0.6625, 0.25, 0.3254464285714286, None) - t: 0.2480330467224121\n",
      "Loss: 3.3973188400268555 - score: (0.5625, 0.3125, 0.3923913043478261, None) - t: 0.24255657196044922\n",
      "Loss: 2.9299166202545166 - score: (0.625, 0.25, 0.34523809523809523, None) - t: 0.2417290210723877\n",
      "Loss: 3.2119810581207275 - score: (0.53125, 0.3125, 0.39322916666666663, None) - t: 0.24142956733703613\n",
      "Loss: 4.267648220062256 - score: (0.46875, 0.1875, 0.2678571428571429, None) - t: 0.24409985542297363\n",
      "Loss: 4.261768341064453 - score: (0.31875, 0.15625, 0.18898809523809526, None) - t: 0.24329900741577148\n",
      "Loss: 3.402904748916626 - score: (0.46875, 0.15625, 0.234375, None) - t: 0.2447490692138672\n",
      "Loss: 3.941133975982666 - score: (0.59375, 0.25, 0.3482954545454545, None) - t: 0.2427823543548584\n",
      "Loss: 3.412539482116699 - score: (0.59375, 0.15625, 0.2308114035087719, None) - t: 0.24357914924621582\n",
      "Loss: 3.4529647827148438 - score: (0.40625, 0.21875, 0.28437500000000004, None) - t: 0.24137425422668457\n",
      "Loss: 3.571882963180542 - score: (0.46875, 0.1875, 0.2678571428571429, None) - t: 0.2422018051147461\n",
      "Loss: 2.9094748497009277 - score: (0.3638392857142857, 0.21875, 0.26458333333333334, None) - t: 0.2514650821685791\n",
      "Loss: 3.7582433223724365 - score: (0.234375, 0.125, 0.15208333333333335, None) - t: 0.24411320686340332\n",
      "Loss: 3.1024558544158936 - score: (0.5625, 0.3125, 0.40166666666666667, None) - t: 0.24381113052368164\n",
      "Loss: 3.7349164485931396 - score: (0.53125, 0.25, 0.32401315789473684, None) - t: 0.24875855445861816\n",
      "Loss: 2.8302013874053955 - score: (0.59765625, 0.34375, 0.4163647342995169, None) - t: 0.24866080284118652\n",
      "Loss: 3.6935667991638184 - score: (0.625, 0.25, 0.34002976190476186, None) - t: 0.24399209022521973\n",
      "Loss: 4.3669304847717285 - score: (0.28125, 0.09375, 0.140625, None) - t: 0.24875712394714355\n",
      "Loss: 2.5115597248077393 - score: (0.784375, 0.375, 0.4717234848484849, None) - t: 0.25420188903808594\n",
      "Loss: 3.2273240089416504 - score: (0.3151041666666667, 0.125, 0.15900735294117646, None) - t: 0.2584519386291504\n",
      "Loss: 2.5822532176971436 - score: (0.6944444444444444, 0.3125, 0.4189583333333333, None) - t: 0.24834513664245605\n",
      "Loss: 4.068129062652588 - score: (0.34375, 0.1875, 0.24264705882352938, None) - t: 0.2519707679748535\n",
      "Loss: 3.957899570465088 - score: (0.5625, 0.1875, 0.27827380952380953, None) - t: 0.24864864349365234\n",
      "Loss: 2.5608246326446533 - score: (0.46875, 0.3125, 0.375, None) - t: 0.2545318603515625\n",
      "Loss: 3.293511390686035 - score: (0.65625, 0.34375, 0.4305555555555555, None) - t: 0.24512529373168945\n",
      "Loss: 4.229860782623291 - score: (0.46875, 0.15625, 0.23229166666666665, None) - t: 0.25107812881469727\n",
      "Loss: 2.5527617931365967 - score: (0.59375, 0.34375, 0.43540669856459324, None) - t: 0.25247836112976074\n",
      "Loss: 3.606785297393799 - score: (0.25892857142857145, 0.15625, 0.18055555555555555, None) - t: 0.24473857879638672\n",
      "Loss: 3.842344284057617 - score: (0.5625, 0.34375, 0.41220238095238093, None) - t: 0.252044677734375\n",
      "Loss: 3.4040393829345703 - score: (0.21484375, 0.15625, 0.18092105263157893, None) - t: 0.24439525604248047\n",
      "Loss: 3.63628888130188 - score: (0.5178571428571428, 0.1875, 0.2230902777777778, None) - t: 0.249739408493042\n",
      "Loss: 3.3008999824523926 - score: (0.4375, 0.25, 0.3181818181818182, None) - t: 0.24942588806152344\n",
      "Loss: 3.622185707092285 - score: (0.35, 0.15625, 0.19374999999999998, None) - t: 0.2511601448059082\n",
      "Loss: 3.3682641983032227 - score: (0.3791666666666667, 0.34375, 0.34531249999999997, None) - t: 0.24973678588867188\n",
      "Loss: 3.2747957706451416 - score: (0.4296875, 0.3125, 0.35254726890756305, None) - t: 0.24955272674560547\n",
      "Loss: 2.563523054122925 - score: (0.5653409090909091, 0.3125, 0.359375, None) - t: 0.2445051670074463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/25 [01:24<16:49, 43.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.5074210166931152 - score: (0.2798029556650246, 0.2413793103448276, 0.25914315569487983, None) - t: 0.2216484546661377\n",
      "Loss: 2.831212282180786 - score: (0.5880681818181819, 0.5, 0.5394345238095237, None) - t: 0.24596023559570312\n",
      "Loss: 3.374818801879883 - score: (0.375, 0.3125, 0.328125, None) - t: 0.24685430526733398\n",
      "Loss: 3.249868392944336 - score: (0.4375, 0.25, 0.3035714285714286, None) - t: 0.2457714080810547\n",
      "Loss: 3.4846560955047607 - score: (0.5, 0.21875, 0.2991071428571429, None) - t: 0.24392938613891602\n",
      "Loss: 2.5046236515045166 - score: (0.6875, 0.21875, 0.32028508771929826, None) - t: 0.24571633338928223\n",
      "Loss: 3.4667458534240723 - score: (0.59375, 0.3125, 0.39943181818181817, None) - t: 0.24668121337890625\n",
      "Loss: 2.3499085903167725 - score: (0.5738636363636364, 0.21875, 0.2525641025641026, None) - t: 0.24506139755249023\n",
      "Loss: 2.952432155609131 - score: (0.3645833333333333, 0.28125, 0.296875, None) - t: 0.24825382232666016\n",
      "Loss: 3.2663486003875732 - score: (0.34375, 0.15625, 0.2098214285714286, None) - t: 0.24617266654968262\n",
      "Loss: 2.352583169937134 - score: (0.625, 0.40625, 0.4887820512820513, None) - t: 0.25144457817077637\n",
      "Loss: 2.647801637649536 - score: (0.53125, 0.34375, 0.41586538461538464, None) - t: 0.2451496124267578\n",
      "Loss: 2.629737377166748 - score: (0.53125, 0.3125, 0.3885869565217392, None) - t: 0.24700641632080078\n",
      "Loss: 3.339230537414551 - score: (0.3125, 0.1875, 0.22916666666666666, None) - t: 0.24426984786987305\n",
      "Loss: 2.472259998321533 - score: (0.625, 0.40625, 0.4887820512820513, None) - t: 0.2460336685180664\n",
      "Loss: 2.9794259071350098 - score: (0.5, 0.3125, 0.38048245614035087, None) - t: 0.2479393482208252\n",
      "Loss: 2.448479413986206 - score: (0.5327380952380952, 0.46875, 0.47929292929292927, None) - t: 0.24327754974365234\n",
      "Loss: 1.9108949899673462 - score: (0.6805555555555556, 0.5625, 0.582093253968254, None) - t: 0.24445748329162598\n",
      "Loss: 2.8348796367645264 - score: (0.59375, 0.4375, 0.4708333333333333, None) - t: 0.24820899963378906\n",
      "Loss: 2.5289700031280518 - score: (0.5669642857142857, 0.34375, 0.3997395833333333, None) - t: 0.2509419918060303\n",
      "Loss: 3.2592408657073975 - score: (0.39732142857142855, 0.28125, 0.3203125, None) - t: 0.2433032989501953\n",
      "Loss: 3.009207010269165 - score: (0.53125, 0.1875, 0.2693452380952381, None) - t: 0.2455587387084961\n",
      "Loss: 2.8518893718719482 - score: (0.3958333333333333, 0.125, 0.18489583333333331, None) - t: 0.2439403533935547\n",
      "Loss: 2.837718963623047 - score: (0.453125, 0.40625, 0.4114583333333333, None) - t: 0.24422883987426758\n",
      "Loss: 2.083613395690918 - score: (0.5282738095238095, 0.4375, 0.4563301282051282, None) - t: 0.25098705291748047\n",
      "Loss: 2.9409828186035156 - score: (0.75, 0.46875, 0.5628434065934066, None) - t: 0.2551910877227783\n",
      "Loss: 2.792621612548828 - score: (0.509375, 0.40625, 0.42782738095238093, None) - t: 0.24600005149841309\n",
      "Loss: 3.235851287841797 - score: (0.5803571428571428, 0.25, 0.2931547619047619, None) - t: 0.2484302520751953\n",
      "Loss: 3.5030014514923096 - score: (0.46875, 0.21875, 0.2982456140350877, None) - t: 0.2466130256652832\n",
      "Loss: 2.895371913909912 - score: (0.5, 0.375, 0.4114583333333333, None) - t: 0.2468113899230957\n",
      "Loss: 2.9166765213012695 - score: (0.5600961538461539, 0.3125, 0.28888888888888886, None) - t: 0.24849605560302734\n",
      "Loss: 3.3656976222991943 - score: (0.35357142857142854, 0.3125, 0.3314393939393939, None) - t: 0.2547163963317871\n",
      "Loss: 2.629309892654419 - score: (0.34791666666666665, 0.28125, 0.30080128205128204, None) - t: 0.2535085678100586\n",
      "Loss: 2.775778293609619 - score: (0.5729166666666667, 0.4375, 0.4718406593406593, None) - t: 0.24855256080627441\n",
      "Loss: 2.721308708190918 - score: (0.571875, 0.40625, 0.44157196969696966, None) - t: 0.24941086769104004\n",
      "Loss: 2.7271862030029297 - score: (0.5078125, 0.3125, 0.35318627450980394, None) - t: 0.25513625144958496\n",
      "Loss: 2.6086292266845703 - score: (0.45052083333333337, 0.40625, 0.42410714285714285, None) - t: 0.2469332218170166\n",
      "Loss: 2.966360092163086 - score: (0.5208333333333333, 0.34375, 0.37589285714285714, None) - t: 0.2434072494506836\n",
      "Loss: 3.0475575923919678 - score: (0.43452380952380953, 0.34375, 0.3747549019607843, None) - t: 0.24469470977783203\n",
      "Loss: 2.908304214477539 - score: (0.48995535714285715, 0.3125, 0.36675347222222227, None) - t: 0.24427151679992676\n",
      "Loss: 2.814054012298584 - score: (0.478125, 0.375, 0.403483893557423, None) - t: 0.24501299858093262\n",
      "Loss: 3.003965377807617 - score: (0.428125, 0.3125, 0.35085227272727276, None) - t: 0.24378633499145508\n",
      "Loss: 2.4715967178344727 - score: (0.29910714285714285, 0.28125, 0.2863782051282051, None) - t: 0.24454355239868164\n",
      "Loss: 2.6165716648101807 - score: (0.28125, 0.25, 0.2546875, None) - t: 0.24404525756835938\n",
      "Loss: 2.9244632720947266 - score: (0.4270833333333333, 0.34375, 0.37419871794871795, None) - t: 0.2519512176513672\n",
      "Loss: 2.802635669708252 - score: (0.56875, 0.375, 0.4239583333333333, None) - t: 0.25045037269592285\n",
      "Loss: 2.8724732398986816 - score: (0.46875, 0.40625, 0.4289772727272727, None) - t: 0.24512553215026855\n",
      "Loss: 3.3825607299804688 - score: (0.3333333333333333, 0.28125, 0.30059523809523814, None) - t: 0.2447221279144287\n",
      "Loss: 2.2715749740600586 - score: (0.5260416666666667, 0.40625, 0.4447916666666667, None) - t: 0.24521303176879883\n",
      "Loss: 2.8663344383239746 - score: (0.46875, 0.1875, 0.2611607142857143, None) - t: 0.24368524551391602\n",
      "Loss: 2.7670276165008545 - score: (0.5472222222222223, 0.28125, 0.33055555555555555, None) - t: 0.248366117477417\n",
      "Loss: 2.6404402256011963 - score: (0.49375, 0.40625, 0.4422348484848485, None) - t: 0.253572940826416\n",
      "Loss: 2.8231451511383057 - score: (0.5385416666666667, 0.375, 0.4109775641025641, None) - t: 0.24798870086669922\n",
      "Loss: 3.759627103805542 - score: (0.18125000000000002, 0.15625, 0.16666666666666669, None) - t: 0.2547924518585205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 3/25 [02:00<15:13, 41.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.9095189571380615 - score: (0.3793103448275862, 0.2413793103448276, 0.24674329501915707, None) - t: 0.22798585891723633\n",
      "Loss: 2.234834671020508 - score: (0.6875, 0.59375, 0.625, None) - t: 0.25049781799316406\n",
      "Loss: 1.7666211128234863 - score: (0.78515625, 0.625, 0.6534801136363637, None) - t: 0.24587297439575195\n",
      "Loss: 1.8658267259597778 - score: (0.734375, 0.59375, 0.6056547619047619, None) - t: 0.2461566925048828\n",
      "Loss: 2.3991878032684326 - score: (0.5859375, 0.5625, 0.5636904761904762, None) - t: 0.24617218971252441\n",
      "Loss: 1.7497574090957642 - score: (0.7535714285714286, 0.5, 0.5605696386946387, None) - t: 0.24708318710327148\n",
      "Loss: 1.9351184368133545 - score: (0.703125, 0.59375, 0.638507326007326, None) - t: 0.24680399894714355\n",
      "Loss: 1.6882929801940918 - score: (0.734375, 0.6875, 0.6979166666666666, None) - t: 0.24686884880065918\n",
      "Loss: 1.8675575256347656 - score: (0.6597222222222222, 0.625, 0.6351338612368024, None) - t: 0.2461528778076172\n",
      "Loss: 2.186174154281616 - score: (0.41796875, 0.40625, 0.37554945054945055, None) - t: 0.2531769275665283\n",
      "Loss: 1.9194430112838745 - score: (0.5989583333333334, 0.5625, 0.5691287878787878, None) - t: 0.24910831451416016\n",
      "Loss: 1.8639211654663086 - score: (0.6927083333333334, 0.625, 0.6485558712121212, None) - t: 0.2534167766571045\n",
      "Loss: 2.1388425827026367 - score: (0.4464285714285714, 0.4375, 0.4338141025641025, None) - t: 0.2540433406829834\n",
      "Loss: 2.003922700881958 - score: (0.46796875, 0.46875, 0.46685606060606055, None) - t: 0.24872612953186035\n",
      "Loss: 1.918032169342041 - score: (0.42534722222222227, 0.4375, 0.4229714912280701, None) - t: 0.24697542190551758\n",
      "Loss: 1.7298104763031006 - score: (0.78125, 0.65625, 0.696496212121212, None) - t: 0.25453925132751465\n",
      "Loss: 1.5289547443389893 - score: (0.6979166666666667, 0.65625, 0.6682692307692307, None) - t: 0.25329065322875977\n",
      "Loss: 2.1370773315429688 - score: (0.5234375, 0.46875, 0.47445436507936506, None) - t: 0.2519075870513916\n",
      "Loss: 1.6586862802505493 - score: (0.75, 0.65625, 0.6738095238095239, None) - t: 0.2521779537200928\n",
      "Loss: 1.724910020828247 - score: (0.5130208333333333, 0.5, 0.5006944444444443, None) - t: 0.24693965911865234\n",
      "Loss: 1.8363863229751587 - score: (0.5677083333333333, 0.5, 0.5221153846153845, None) - t: 0.246049165725708\n",
      "Loss: 1.91152024269104 - score: (0.5613839285714286, 0.53125, 0.5372023809523809, None) - t: 0.24783897399902344\n",
      "Loss: 1.7635153532028198 - score: (0.5677083333333334, 0.53125, 0.5444055944055943, None) - t: 0.24958181381225586\n",
      "Loss: 1.5509231090545654 - score: (0.625, 0.5625, 0.5703125, None) - t: 0.24659371376037598\n",
      "Loss: 1.975257396697998 - score: (0.6953125, 0.5625, 0.5980654761904762, None) - t: 0.2554488182067871\n",
      "Loss: 2.105180025100708 - score: (0.546875, 0.46875, 0.48409090909090907, None) - t: 0.24844646453857422\n",
      "Loss: 2.0062355995178223 - score: (0.5401785714285714, 0.40625, 0.42724358974358967, None) - t: 0.25123167037963867\n",
      "Loss: 2.548299551010132 - score: (0.35677083333333337, 0.3125, 0.3303571428571429, None) - t: 0.24525046348571777\n",
      "Loss: 1.8831058740615845 - score: (0.6026785714285714, 0.53125, 0.5436334498834499, None) - t: 0.24767565727233887\n",
      "Loss: 1.5761072635650635 - score: (0.654265873015873, 0.5625, 0.5886948529411765, None) - t: 0.24597978591918945\n",
      "Loss: 1.9444390535354614 - score: (0.6510416666666666, 0.65625, 0.6482142857142857, None) - t: 0.250887393951416\n",
      "Loss: 1.5812783241271973 - score: (0.66015625, 0.625, 0.6275452488687783, None) - t: 0.24843096733093262\n",
      "Loss: 2.2806265354156494 - score: (0.5, 0.4375, 0.425, None) - t: 0.2498793601989746\n",
      "Loss: 2.1032323837280273 - score: (0.5520833333333333, 0.5, 0.50625, None) - t: 0.24239373207092285\n",
      "Loss: 1.8549950122833252 - score: (0.5885416666666667, 0.5, 0.5182291666666666, None) - t: 0.24926471710205078\n",
      "Loss: 1.816380262374878 - score: (0.6145833333333333, 0.5625, 0.5729166666666666, None) - t: 0.2504708766937256\n",
      "Loss: 2.3747804164886475 - score: (0.3802083333333333, 0.34375, 0.35267857142857145, None) - t: 0.25238728523254395\n",
      "Loss: 2.1531689167022705 - score: (0.4854910714285714, 0.4375, 0.4525641025641025, None) - t: 0.24791717529296875\n",
      "Loss: 1.4839297533035278 - score: (0.78515625, 0.65625, 0.6848369155354449, None) - t: 0.24442172050476074\n",
      "Loss: 2.0489799976348877 - score: (0.6428571428571428, 0.5, 0.553921568627451, None) - t: 0.24373960494995117\n",
      "Loss: 2.265329360961914 - score: (0.36250000000000004, 0.3125, 0.3333333333333333, None) - t: 0.24602437019348145\n",
      "Loss: 1.879934549331665 - score: (0.4291666666666667, 0.4375, 0.43068181818181817, None) - t: 0.24298095703125\n",
      "Loss: 2.0988428592681885 - score: (0.45833333333333337, 0.46875, 0.4583333333333333, None) - t: 0.24315142631530762\n",
      "Loss: 1.8189078569412231 - score: (0.5104166666666667, 0.5, 0.5016025641025641, None) - t: 0.24835419654846191\n",
      "Loss: 2.0034894943237305 - score: (0.4131944444444444, 0.40625, 0.4045758928571429, None) - t: 0.24661922454833984\n",
      "Loss: 1.869736909866333 - score: (0.646875, 0.53125, 0.5690972222222221, None) - t: 0.24582529067993164\n",
      "Loss: 1.712583303451538 - score: (0.5729166666666666, 0.5, 0.5145089285714286, None) - t: 0.24780654907226562\n",
      "Loss: 2.164227247238159 - score: (0.515625, 0.46875, 0.4684343434343434, None) - t: 0.24677252769470215\n",
      "Loss: 2.4531466960906982 - score: (0.4229910714285714, 0.4375, 0.42548076923076916, None) - t: 0.25397729873657227\n",
      "Loss: 2.0376439094543457 - score: (0.5198863636363636, 0.4375, 0.4743303571428572, None) - t: 0.2477588653564453\n",
      "Loss: 2.2046706676483154 - score: (0.4125, 0.3125, 0.3336309523809523, None) - t: 0.24614572525024414\n",
      "Loss: 2.029430627822876 - score: (0.5625, 0.5625, 0.5625, None) - t: 0.24541258811950684\n",
      "Loss: 2.09281849861145 - score: (0.4875, 0.40625, 0.4072916666666666, None) - t: 0.24562811851501465\n",
      "Loss: 2.4406704902648926 - score: (0.47395833333333337, 0.375, 0.4072698135198135, None) - t: 0.2526843547821045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 4/25 [02:36<13:55, 39.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.712647557258606 - score: (0.5004926108374385, 0.4827586206896552, 0.4827586206896552, None) - t: 0.21894049644470215\n",
      "Loss: 1.364761471748352 - score: (0.6822916666666666, 0.6875, 0.6749999999999999, None) - t: 0.24702119827270508\n",
      "Loss: 1.5607997179031372 - score: (0.6197916666666666, 0.5625, 0.5625, None) - t: 0.24505376815795898\n",
      "Loss: 1.4622180461883545 - score: (0.78125, 0.71875, 0.7317708333333333, None) - t: 0.2466127872467041\n",
      "Loss: 1.080470085144043 - score: (0.9032738095238095, 0.71875, 0.7530381944444444, None) - t: 0.24831461906433105\n",
      "Loss: 1.1821550130844116 - score: (0.75, 0.65625, 0.646780303030303, None) - t: 0.2473735809326172\n",
      "Loss: 1.3590643405914307 - score: (0.6875, 0.59375, 0.6041666666666666, None) - t: 0.2474079132080078\n",
      "Loss: 0.8535659909248352 - score: (0.875, 0.875, 0.875, None) - t: 0.24779987335205078\n",
      "Loss: 1.1160372495651245 - score: (0.640625, 0.6875, 0.65625, None) - t: 0.24410557746887207\n",
      "Loss: 1.030616044998169 - score: (0.75, 0.71875, 0.71875, None) - t: 0.24831390380859375\n",
      "Loss: 1.0780308246612549 - score: (0.828125, 0.6875, 0.7145833333333333, None) - t: 0.24814105033874512\n",
      "Loss: 1.1990010738372803 - score: (0.8020833333333333, 0.6875, 0.709375, None) - t: 0.24454450607299805\n",
      "Loss: 0.8875349760055542 - score: (0.86875, 0.78125, 0.8059895833333333, None) - t: 0.2463092803955078\n",
      "Loss: 1.6834033727645874 - score: (0.7604166666666666, 0.59375, 0.6501201923076922, None) - t: 0.24873757362365723\n",
      "Loss: 0.8836326003074646 - score: (0.83125, 0.78125, 0.7855113636363635, None) - t: 0.2505760192871094\n",
      "Loss: 1.1707448959350586 - score: (0.625, 0.625, 0.625, None) - t: 0.24532437324523926\n",
      "Loss: 1.1384384632110596 - score: (0.6875, 0.6875, 0.6875, None) - t: 0.24805521965026855\n",
      "Loss: 0.9720979332923889 - score: (0.7955729166666666, 0.78125, 0.7787878787878787, None) - t: 0.25054383277893066\n",
      "Loss: 1.1607550382614136 - score: (0.859375, 0.8125, 0.8229166666666666, None) - t: 0.24658513069152832\n",
      "Loss: 1.032343864440918 - score: (0.7366071428571428, 0.6875, 0.6986607142857142, None) - t: 0.24733424186706543\n",
      "Loss: 1.1632524728775024 - score: (0.6741071428571428, 0.65625, 0.6569940476190477, None) - t: 0.24549627304077148\n",
      "Loss: 1.1696150302886963 - score: (0.7899305555555556, 0.6875, 0.6793154761904762, None) - t: 0.24930024147033691\n",
      "Loss: 1.1354639530181885 - score: (0.8203125, 0.78125, 0.7926968864468864, None) - t: 0.24959897994995117\n",
      "Loss: 1.0337353944778442 - score: (0.84375, 0.8125, 0.8229166666666666, None) - t: 0.2561361789703369\n",
      "Loss: 0.7445260286331177 - score: (0.81875, 0.8125, 0.8133169934640523, None) - t: 0.24948763847351074\n",
      "Loss: 1.0862467288970947 - score: (0.8385416666666667, 0.78125, 0.8074737762237761, None) - t: 0.2526085376739502\n",
      "Loss: 1.3792611360549927 - score: (0.6822916666666667, 0.625, 0.6318108974358974, None) - t: 0.2512545585632324\n",
      "Loss: 0.9428566694259644 - score: (0.7013888888888888, 0.71875, 0.7049369747899159, None) - t: 0.2491607666015625\n",
      "Loss: 1.0168859958648682 - score: (0.796875, 0.78125, 0.7847222222222222, None) - t: 0.248854398727417\n",
      "Loss: 0.9550093412399292 - score: (0.81640625, 0.78125, 0.79375, None) - t: 0.25563549995422363\n",
      "Loss: 1.1327555179595947 - score: (0.8375, 0.8125, 0.8154513888888889, None) - t: 0.24802613258361816\n",
      "Loss: 1.0259082317352295 - score: (0.7857142857142857, 0.75, 0.7598824786324787, None) - t: 0.24750018119812012\n",
      "Loss: 1.1927571296691895 - score: (0.6927083333333334, 0.65625, 0.6670454545454545, None) - t: 0.2533085346221924\n",
      "Loss: 1.5645225048065186 - score: (0.625, 0.59375, 0.6041666666666666, None) - t: 0.24982881546020508\n",
      "Loss: 0.9832217693328857 - score: (0.7734375, 0.78125, 0.7720238095238094, None) - t: 0.250805139541626\n",
      "Loss: 0.9898443818092346 - score: (0.80078125, 0.6875, 0.7000334224598931, None) - t: 0.24734878540039062\n",
      "Loss: 1.1041332483291626 - score: (0.78515625, 0.71875, 0.7392045454545454, None) - t: 0.25027036666870117\n",
      "Loss: 1.089626669883728 - score: (0.78515625, 0.75, 0.7583333333333333, None) - t: 0.24953603744506836\n",
      "Loss: 1.3953616619110107 - score: (0.6676136363636364, 0.65625, 0.6541666666666667, None) - t: 0.24869298934936523\n",
      "Loss: 0.86097252368927 - score: (0.6875, 0.6875, 0.6770833333333334, None) - t: 0.2500495910644531\n",
      "Loss: 1.0824503898620605 - score: (0.7608901515151515, 0.75, 0.7455357142857144, None) - t: 0.2506120204925537\n",
      "Loss: 0.9744263291358948 - score: (0.84375, 0.8125, 0.8229166666666666, None) - t: 0.25674867630004883\n",
      "Loss: 1.3260493278503418 - score: (0.625, 0.59375, 0.6079545454545454, None) - t: 0.2535996437072754\n",
      "Loss: 1.1619876623153687 - score: (0.75, 0.75, 0.75, None) - t: 0.2494344711303711\n",
      "Loss: 1.4688266515731812 - score: (0.5885416666666666, 0.59375, 0.5823863636363635, None) - t: 0.2542424201965332\n",
      "Loss: 0.9760614633560181 - score: (0.6770833333333333, 0.65625, 0.6658653846153846, None) - t: 0.2524864673614502\n",
      "Loss: 1.0701677799224854 - score: (0.8125, 0.8125, 0.8020833333333334, None) - t: 0.24904274940490723\n",
      "Loss: 1.3108233213424683 - score: (0.68125, 0.65625, 0.6588541666666666, None) - t: 0.2554738521575928\n",
      "Loss: 1.143236517906189 - score: (0.6300223214285714, 0.625, 0.6258484162895928, None) - t: 0.24820613861083984\n",
      "Loss: 1.6468993425369263 - score: (0.565625, 0.53125, 0.543560606060606, None) - t: 0.24707508087158203\n",
      "Loss: 1.3560431003570557 - score: (0.6875, 0.65625, 0.6666666666666667, None) - t: 0.24988293647766113\n",
      "Loss: 1.428354263305664 - score: (0.6428571428571428, 0.625, 0.625, None) - t: 0.2461555004119873\n",
      "Loss: 1.2817445993423462 - score: (0.546875, 0.5625, 0.5520833333333333, None) - t: 0.24811530113220215\n",
      "Loss: 1.4010428190231323 - score: (0.6614583333333333, 0.625, 0.6328125, None) - t: 0.24454522132873535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 5/25 [03:14<13:04, 39.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.5568526983261108 - score: (0.5885057471264369, 0.5172413793103449, 0.541871921182266, None) - t: 0.21711516380310059\n",
      "Loss: 0.5805186033248901 - score: (0.8308035714285714, 0.8125, 0.8118444055944056, None) - t: 0.24634790420532227\n",
      "Loss: 0.6255047917366028 - score: (0.8958333333333333, 0.8125, 0.8291666666666666, None) - t: 0.24834609031677246\n",
      "Loss: 0.4547421336174011 - score: (0.8576388888888888, 0.875, 0.8618607954545454, None) - t: 0.24651741981506348\n",
      "Loss: 0.790121853351593 - score: (0.8125, 0.6875, 0.7277777777777777, None) - t: 0.24593591690063477\n",
      "Loss: 0.3718580901622772 - score: (1.0, 0.9375, 0.9583333333333334, None) - t: 0.24796199798583984\n",
      "Loss: 0.5318841934204102 - score: (0.93125, 0.875, 0.8794642857142857, None) - t: 0.24822211265563965\n",
      "Loss: 0.5514596700668335 - score: (0.875, 0.875, 0.875, None) - t: 0.24714946746826172\n",
      "Loss: 0.5096904039382935 - score: (0.90625, 0.875, 0.8854166666666666, None) - t: 0.24696135520935059\n",
      "Loss: 0.557156503200531 - score: (0.8802083333333334, 0.875, 0.875, None) - t: 0.24643945693969727\n",
      "Loss: 0.47527191042900085 - score: (0.8854166666666666, 0.90625, 0.89375, None) - t: 0.25186610221862793\n",
      "Loss: 0.41091644763946533 - score: (0.96875, 0.90625, 0.9270833333333333, None) - t: 0.24843978881835938\n",
      "Loss: 0.6790351271629333 - score: (0.828125, 0.8125, 0.8125, None) - t: 0.24714946746826172\n",
      "Loss: 0.5557210445404053 - score: (0.8459821428571428, 0.84375, 0.828125, None) - t: 0.24265384674072266\n",
      "Loss: 0.6932251453399658 - score: (0.78125, 0.78125, 0.78125, None) - t: 0.2481098175048828\n",
      "Loss: 0.8942892551422119 - score: (0.8489583333333334, 0.75, 0.7757260101010102, None) - t: 0.24626636505126953\n",
      "Loss: 0.5312323570251465 - score: (0.890625, 0.875, 0.875, None) - t: 0.24509763717651367\n",
      "Loss: 0.7021247148513794 - score: (0.8055555555555556, 0.78125, 0.7747395833333333, None) - t: 0.2471022605895996\n",
      "Loss: 0.514377772808075 - score: (0.87890625, 0.875, 0.8751225490196078, None) - t: 0.24696898460388184\n",
      "Loss: 0.7650381326675415 - score: (0.7220982142857143, 0.71875, 0.71875, None) - t: 0.2468574047088623\n",
      "Loss: 0.724573016166687 - score: (0.8482142857142857, 0.78125, 0.8018648018648018, None) - t: 0.24939823150634766\n",
      "Loss: 0.48763105273246765 - score: (0.875, 0.875, 0.875, None) - t: 0.2478351593017578\n",
      "Loss: 0.45549869537353516 - score: (0.8354166666666667, 0.84375, 0.8263888888888888, None) - t: 0.2511405944824219\n",
      "Loss: 0.3980748951435089 - score: (0.875, 0.875, 0.875, None) - t: 0.2466897964477539\n",
      "Loss: 0.5807441473007202 - score: (0.90625, 0.90625, 0.90625, None) - t: 0.2479569911956787\n",
      "Loss: 0.7636868953704834 - score: (0.7317708333333333, 0.71875, 0.7020833333333334, None) - t: 0.25282764434814453\n",
      "Loss: 0.38958990573883057 - score: (1.0, 0.96875, 0.9791666666666666, None) - t: 0.24518394470214844\n",
      "Loss: 0.7608262896537781 - score: (0.84375, 0.8125, 0.8175595238095238, None) - t: 0.24695849418640137\n",
      "Loss: 1.1129390001296997 - score: (0.7366071428571428, 0.71875, 0.71875, None) - t: 0.25565505027770996\n",
      "Loss: 0.517511248588562 - score: (0.953125, 0.9375, 0.9375, None) - t: 0.2514338493347168\n",
      "Loss: 0.6648759841918945 - score: (0.8229166666666667, 0.78125, 0.790246212121212, None) - t: 0.24471783638000488\n",
      "Loss: 0.7886037826538086 - score: (0.78125, 0.75, 0.7604166666666666, None) - t: 0.24584102630615234\n",
      "Loss: 0.701583981513977 - score: (0.796875, 0.8125, 0.8020833333333333, None) - t: 0.24719500541687012\n",
      "Loss: 0.5684956312179565 - score: (0.7388392857142857, 0.75, 0.7376602564102565, None) - t: 0.25264787673950195\n",
      "Loss: 0.6965484619140625 - score: (0.84765625, 0.84375, 0.8438725490196078, None) - t: 0.24492526054382324\n",
      "Loss: 0.7327991724014282 - score: (0.796875, 0.75, 0.7604166666666666, None) - t: 0.24614596366882324\n",
      "Loss: 0.5138303637504578 - score: (0.90625, 0.90625, 0.90625, None) - t: 0.2528409957885742\n",
      "Loss: 0.6414932608604431 - score: (0.828125, 0.8125, 0.8162878787878787, None) - t: 0.24879932403564453\n",
      "Loss: 0.897063136100769 - score: (0.796875, 0.78125, 0.7852564102564101, None) - t: 0.24573230743408203\n",
      "Loss: 0.47317206859588623 - score: (0.890625, 0.90625, 0.8958333333333333, None) - t: 0.25035977363586426\n",
      "Loss: 0.748356282711029 - score: (0.7847222222222222, 0.78125, 0.779936974789916, None) - t: 0.24756789207458496\n",
      "Loss: 0.6882608532905579 - score: (0.921875, 0.875, 0.8854166666666666, None) - t: 0.2441091537475586\n",
      "Loss: 0.9371422529220581 - score: (0.7572916666666667, 0.71875, 0.7307692307692307, None) - t: 0.2465367317199707\n",
      "Loss: 1.0830531120300293 - score: (0.7375, 0.71875, 0.7173402255639099, None) - t: 0.2453017234802246\n",
      "Loss: 1.1256799697875977 - score: (0.7552083333333334, 0.75, 0.7502185314685315, None) - t: 0.24641704559326172\n",
      "Loss: 0.5462543964385986 - score: (0.90625, 0.90625, 0.90625, None) - t: 0.24701261520385742\n",
      "Loss: 0.7939457893371582 - score: (0.75390625, 0.6875, 0.7024305555555556, None) - t: 0.2533876895904541\n",
      "Loss: 0.7356983423233032 - score: (0.8125, 0.8125, 0.8125, None) - t: 0.24476861953735352\n",
      "Loss: 0.8088504076004028 - score: (0.853125, 0.8125, 0.8140625, None) - t: 0.246262788772583\n",
      "Loss: 0.8352723121643066 - score: (0.84375, 0.78125, 0.8020833333333333, None) - t: 0.25028324127197266\n",
      "Loss: 0.8816193342208862 - score: (0.7552083333333334, 0.75, 0.7305871212121212, None) - t: 0.24572205543518066\n",
      "Loss: 0.5691389441490173 - score: (0.83203125, 0.8125, 0.8046285822021115, None) - t: 0.24426603317260742\n",
      "Loss: 0.759200930595398 - score: (0.7552083333333334, 0.71875, 0.7319055944055944, None) - t: 0.24802350997924805\n",
      "Loss: 1.079228401184082 - score: (0.78125, 0.75, 0.7625, None) - t: 0.251173734664917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 6/25 [04:03<13:19, 42.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9551457166671753 - score: (0.7807881773399015, 0.7241379310344828, 0.735042735042735, None) - t: 0.21750783920288086\n",
      "Loss: 0.37941503524780273 - score: (0.9114583333333334, 0.90625, 0.9024621212121211, None) - t: 0.24802446365356445\n",
      "Loss: 0.438060462474823 - score: (0.8697916666666666, 0.875, 0.8662878787878787, None) - t: 0.24921870231628418\n",
      "Loss: 0.31053751707077026 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24663162231445312\n",
      "Loss: 0.2854231297969818 - score: (0.953125, 0.9375, 0.9395833333333334, None) - t: 0.24818038940429688\n",
      "Loss: 0.2703598141670227 - score: (0.9090909090909091, 0.90625, 0.905952380952381, None) - t: 0.2446274757385254\n",
      "Loss: 0.3579314351081848 - score: (0.90625, 0.90625, 0.90625, None) - t: 0.24680089950561523\n",
      "Loss: 0.2849922776222229 - score: (0.9375, 0.9375, 0.9375, None) - t: 0.24619436264038086\n",
      "Loss: 0.4448101818561554 - score: (0.90625, 0.875, 0.8854166666666666, None) - t: 0.2489621639251709\n",
      "Loss: 0.4259703457355499 - score: (0.9125, 0.90625, 0.9071637426900585, None) - t: 0.24832606315612793\n",
      "Loss: 0.44017481803894043 - score: (0.8125, 0.84375, 0.8229166666666666, None) - t: 0.24661707878112793\n",
      "Loss: 0.417197048664093 - score: (0.9140625, 0.90625, 0.90625, None) - t: 0.24408221244812012\n",
      "Loss: 0.21764367818832397 - score: (0.94140625, 0.9375, 0.9373397435897435, None) - t: 0.24701285362243652\n",
      "Loss: 0.4539027214050293 - score: (0.890625, 0.84375, 0.8529017857142858, None) - t: 0.25012707710266113\n",
      "Loss: 0.6736361980438232 - score: (0.75, 0.75, 0.75, None) - t: 0.25327348709106445\n",
      "Loss: 0.26412856578826904 - score: (0.9427083333333334, 0.9375, 0.9377185314685315, None) - t: 0.2499864101409912\n",
      "Loss: 0.29524028301239014 - score: (0.921875, 0.90625, 0.90625, None) - t: 0.24549484252929688\n",
      "Loss: 0.36748385429382324 - score: (0.875, 0.90625, 0.8854166666666666, None) - t: 0.2505819797515869\n",
      "Loss: 0.3690332770347595 - score: (0.8888888888888888, 0.875, 0.8684895833333333, None) - t: 0.24685955047607422\n",
      "Loss: 0.4638654589653015 - score: (0.8229166666666666, 0.84375, 0.83125, None) - t: 0.2444615364074707\n",
      "Loss: 0.3488491475582123 - score: (0.88125, 0.875, 0.8715277777777778, None) - t: 0.24564790725708008\n",
      "Loss: 0.6376775503158569 - score: (0.8072916666666666, 0.6875, 0.7151988636363635, None) - t: 0.24430561065673828\n",
      "Loss: 0.47633814811706543 - score: (0.9125, 0.875, 0.8883169934640522, None) - t: 0.24563002586364746\n",
      "Loss: 0.47497761249542236 - score: (0.875, 0.875, 0.875, None) - t: 0.2449326515197754\n",
      "Loss: 0.32659590244293213 - score: (0.9375, 0.90625, 0.9166666666666666, None) - t: 0.2446134090423584\n",
      "Loss: 0.41695207357406616 - score: (0.90625, 0.90625, 0.90625, None) - t: 0.24407649040222168\n",
      "Loss: 0.4615853428840637 - score: (0.828125, 0.84375, 0.8333333333333334, None) - t: 0.24491429328918457\n",
      "Loss: 0.48148027062416077 - score: (0.8625, 0.875, 0.8642037786774628, None) - t: 0.24618124961853027\n",
      "Loss: 0.18494603037834167 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24256682395935059\n",
      "Loss: 0.4913496673107147 - score: (0.8375, 0.8125, 0.81640625, None) - t: 0.24327683448791504\n",
      "Loss: 0.2615378499031067 - score: (0.9375, 0.9375, 0.9375, None) - t: 0.24659109115600586\n",
      "Loss: 0.4162035286426544 - score: (0.90625, 0.90625, 0.90625, None) - t: 0.24552464485168457\n",
      "Loss: 0.44268444180488586 - score: (0.890625, 0.875, 0.8793859649122807, None) - t: 0.24690604209899902\n",
      "Loss: 0.5339007377624512 - score: (0.88125, 0.875, 0.8758169934640523, None) - t: 0.24598336219787598\n",
      "Loss: 0.3531802296638489 - score: (0.8854166666666666, 0.90625, 0.89375, None) - t: 0.24692249298095703\n",
      "Loss: 0.3414537310600281 - score: (0.921875, 0.9375, 0.9270833333333333, None) - t: 0.25441765785217285\n",
      "Loss: 0.447941392660141 - score: (0.9, 0.875, 0.8776041666666666, None) - t: 0.2550983428955078\n",
      "Loss: 0.4131992757320404 - score: (0.859375, 0.875, 0.8645833333333334, None) - t: 0.24573516845703125\n",
      "Loss: 0.507962167263031 - score: (0.84375, 0.8125, 0.8145833333333333, None) - t: 0.2450857162475586\n",
      "Loss: 0.25820833444595337 - score: (0.9375, 0.9375, 0.9375, None) - t: 0.24514198303222656\n",
      "Loss: 0.6142936944961548 - score: (0.765625, 0.78125, 0.7708333333333334, None) - t: 0.24582409858703613\n",
      "Loss: 0.4363948702812195 - score: (0.975, 0.90625, 0.9270833333333333, None) - t: 0.2524147033691406\n",
      "Loss: 0.4157373309135437 - score: (0.9375, 0.9375, 0.9375, None) - t: 0.2468090057373047\n",
      "Loss: 0.41118255257606506 - score: (0.8950892857142857, 0.90625, 0.8959935897435898, None) - t: 0.25153136253356934\n",
      "Loss: 0.5393581986427307 - score: (0.828125, 0.8125, 0.8091517857142857, None) - t: 0.2511587142944336\n",
      "Loss: 0.46543407440185547 - score: (0.84375, 0.8125, 0.8184523809523809, None) - t: 0.2562747001647949\n",
      "Loss: 0.41062647104263306 - score: (0.9107142857142857, 0.875, 0.8851981351981352, None) - t: 0.24666690826416016\n",
      "Loss: 0.45215553045272827 - score: (0.875, 0.875, 0.875, None) - t: 0.24864530563354492\n",
      "Loss: 0.7548098564147949 - score: (0.765625, 0.78125, 0.7708333333333333, None) - t: 0.2511610984802246\n",
      "Loss: 0.39037907123565674 - score: (0.9114583333333334, 0.90625, 0.9069264069264069, None) - t: 0.25211620330810547\n",
      "Loss: 0.15625235438346863 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24442768096923828\n",
      "Loss: 0.364279180765152 - score: (0.90625, 0.90625, 0.90625, None) - t: 0.25246500968933105\n",
      "Loss: 0.4812787175178528 - score: (0.8638392857142857, 0.875, 0.8640491452991452, None) - t: 0.25314903259277344\n",
      "Loss: 0.41485846042633057 - score: (0.890625, 0.875, 0.875, None) - t: 0.24497008323669434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 7/25 [04:50<13:06, 43.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.462769091129303 - score: (0.8706896551724138, 0.8620689655172413, 0.8633825944170772, None) - t: 0.221480131149292\n",
      "Loss: 0.13564753532409668 - score: (0.9722222222222222, 0.96875, 0.9686274509803922, None) - t: 0.24392366409301758\n",
      "Loss: 0.21275025606155396 - score: (0.94375, 0.90625, 0.9173611111111111, None) - t: 0.24715089797973633\n",
      "Loss: 0.17208480834960938 - score: (0.9375, 0.90625, 0.9166666666666666, None) - t: 0.24441123008728027\n",
      "Loss: 0.2037065178155899 - score: (0.9375, 0.9375, 0.9375, None) - t: 0.24598240852355957\n",
      "Loss: 0.14573323726654053 - score: (0.9427083333333334, 0.96875, 0.9545454545454546, None) - t: 0.24740171432495117\n",
      "Loss: 0.22354696691036224 - score: (0.9419642857142857, 0.9375, 0.9372814685314685, None) - t: 0.24541997909545898\n",
      "Loss: 0.23931409418582916 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2532525062561035\n",
      "Loss: 0.25269219279289246 - score: (0.90625, 0.90625, 0.90625, None) - t: 0.24529409408569336\n",
      "Loss: 0.17829956114292145 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.25022411346435547\n",
      "Loss: 0.30364346504211426 - score: (0.9375, 0.9375, 0.9375, None) - t: 0.25133323669433594\n",
      "Loss: 0.20601989328861237 - score: (1.0, 0.96875, 0.9791666666666666, None) - t: 0.2484745979309082\n",
      "Loss: 0.1628713607788086 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.25116515159606934\n",
      "Loss: 0.2858150899410248 - score: (0.890625, 0.90625, 0.8958333333333334, None) - t: 0.24673819541931152\n",
      "Loss: 0.10625633597373962 - score: (1.0, 1.0, 1.0, None) - t: 0.24762582778930664\n",
      "Loss: 0.18608973920345306 - score: (0.9409722222222222, 0.9375, 0.9366830065359477, None) - t: 0.24382781982421875\n",
      "Loss: 0.38829147815704346 - score: (0.921875, 0.875, 0.8875, None) - t: 0.24641633033752441\n",
      "Loss: 0.22426612675189972 - score: (0.94140625, 0.90625, 0.9165064102564102, None) - t: 0.2487475872039795\n",
      "Loss: 0.4493385851383209 - score: (0.9375, 0.90625, 0.9166666666666666, None) - t: 0.24491000175476074\n",
      "Loss: 0.4045041799545288 - score: (0.796875, 0.8125, 0.8020833333333333, None) - t: 0.24406051635742188\n",
      "Loss: 0.3833633363246918 - score: (0.9097222222222222, 0.875, 0.8811274509803921, None) - t: 0.2496325969696045\n",
      "Loss: 0.35627979040145874 - score: (0.984375, 0.90625, 0.930871212121212, None) - t: 0.24640178680419922\n",
      "Loss: 0.21393711864948273 - score: (0.96875, 0.9375, 0.9479166666666666, None) - t: 0.2461693286895752\n",
      "Loss: 0.07783126831054688 - score: (1.0, 1.0, 1.0, None) - t: 0.24890804290771484\n",
      "Loss: 0.1765446662902832 - score: (0.96875, 0.9375, 0.9479166666666666, None) - t: 0.2418825626373291\n",
      "Loss: 0.1295047253370285 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24238991737365723\n",
      "Loss: 0.46584150195121765 - score: (0.84375, 0.84375, 0.84375, None) - t: 0.24188661575317383\n",
      "Loss: 0.28283053636550903 - score: (0.9375, 0.9375, 0.9375, None) - t: 0.2418959140777588\n",
      "Loss: 0.18548309803009033 - score: (0.9453125, 0.9375, 0.9383116883116882, None) - t: 0.25028371810913086\n",
      "Loss: 0.34402766823768616 - score: (0.8794642857142857, 0.875, 0.8752828054298643, None) - t: 0.24760913848876953\n",
      "Loss: 0.31934142112731934 - score: (0.93125, 0.875, 0.8890625000000001, None) - t: 0.24505972862243652\n",
      "Loss: 0.24690347909927368 - score: (0.89453125, 0.90625, 0.8960526315789474, None) - t: 0.2492380142211914\n",
      "Loss: 0.27107226848602295 - score: (0.890625, 0.90625, 0.8958333333333334, None) - t: 0.24871826171875\n",
      "Loss: 0.4674413204193115 - score: (0.875, 0.84375, 0.8541666666666666, None) - t: 0.2519056797027588\n",
      "Loss: 0.2530021667480469 - score: (0.9166666666666666, 0.9375, 0.925, None) - t: 0.25298643112182617\n",
      "Loss: 0.4228995144367218 - score: (0.875, 0.90625, 0.8854166666666666, None) - t: 0.24686288833618164\n",
      "Loss: 0.1260545253753662 - score: (1.0, 1.0, 1.0, None) - t: 0.25059080123901367\n",
      "Loss: 0.20733503997325897 - score: (0.9513888888888888, 0.9375, 0.93515625, None) - t: 0.24596834182739258\n",
      "Loss: 0.1744850128889084 - score: (0.953125, 0.96875, 0.9583333333333334, None) - t: 0.2524571418762207\n",
      "Loss: 0.4569520354270935 - score: (0.875, 0.875, 0.8666666666666666, None) - t: 0.2472529411315918\n",
      "Loss: 0.4146586060523987 - score: (0.8950892857142857, 0.84375, 0.8492411387631976, None) - t: 0.2536005973815918\n",
      "Loss: 0.42960312962532043 - score: (0.8828125, 0.875, 0.8720238095238095, None) - t: 0.24701952934265137\n",
      "Loss: 0.34509947896003723 - score: (0.9375, 0.90625, 0.9166666666666666, None) - t: 0.25104308128356934\n",
      "Loss: 0.45386192202568054 - score: (0.875, 0.84375, 0.85625, None) - t: 0.24477148056030273\n",
      "Loss: 0.41546517610549927 - score: (0.9375, 0.84375, 0.8792892156862745, None) - t: 0.25080347061157227\n",
      "Loss: 0.607016921043396 - score: (0.84375, 0.84375, 0.84375, None) - t: 0.2465987205505371\n",
      "Loss: 0.3020419776439667 - score: (0.9114583333333334, 0.90625, 0.9059343434343434, None) - t: 0.24507427215576172\n",
      "Loss: 0.3633251488208771 - score: (0.90625, 0.90625, 0.90625, None) - t: 0.24806451797485352\n",
      "Loss: 0.41349098086357117 - score: (0.8169642857142857, 0.8125, 0.8084935897435896, None) - t: 0.24607300758361816\n",
      "Loss: 0.3321721851825714 - score: (0.9375, 0.875, 0.9023026315789475, None) - t: 0.24377989768981934\n",
      "Loss: 0.3986473083496094 - score: (0.9166666666666666, 0.90625, 0.9041666666666667, None) - t: 0.24712181091308594\n",
      "Loss: 0.34429237246513367 - score: (0.8645833333333333, 0.84375, 0.8447916666666666, None) - t: 0.24767136573791504\n",
      "Loss: 0.771690309047699 - score: (0.7229166666666667, 0.71875, 0.7034970238095237, None) - t: 0.24704885482788086\n",
      "Loss: 0.3886270225048065 - score: (0.88125, 0.84375, 0.8551587301587301, None) - t: 0.2539818286895752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 8/25 [05:26<11:44, 41.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.43434619903564453 - score: (0.8620689655172413, 0.8620689655172413, 0.8620689655172413, None) - t: 0.22272133827209473\n",
      "Loss: 0.12587955594062805 - score: (0.9791666666666666, 0.96875, 0.96875, None) - t: 0.2488570213317871\n",
      "Loss: 0.15642181038856506 - score: (0.96875, 0.9375, 0.95, None) - t: 0.2492365837097168\n",
      "Loss: 0.20659469068050385 - score: (1.0, 0.96875, 0.9791666666666666, None) - t: 0.24801206588745117\n",
      "Loss: 0.10934224724769592 - score: (1.0, 1.0, 1.0, None) - t: 0.24552106857299805\n",
      "Loss: 0.21280711889266968 - score: (0.9114583333333334, 0.90625, 0.9067513368983957, None) - t: 0.2455294132232666\n",
      "Loss: 0.2701762318611145 - score: (0.890625, 0.90625, 0.8958333333333333, None) - t: 0.24550127983093262\n",
      "Loss: 0.1075071394443512 - score: (0.9765625, 0.96875, 0.9657738095238094, None) - t: 0.2496049404144287\n",
      "Loss: 0.14857545495033264 - score: (1.0, 0.96875, 0.9791666666666666, None) - t: 0.24596333503723145\n",
      "Loss: 0.054061055183410645 - score: (1.0, 1.0, 1.0, None) - t: 0.24585247039794922\n",
      "Loss: 0.2833557724952698 - score: (0.953125, 0.90625, 0.9166666666666666, None) - t: 0.24861383438110352\n",
      "Loss: 0.3563900291919708 - score: (0.875, 0.84375, 0.8541666666666666, None) - t: 0.24454045295715332\n",
      "Loss: 0.3228342831134796 - score: (0.859375, 0.84375, 0.85, None) - t: 0.24621796607971191\n",
      "Loss: 0.19996921718120575 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2514045238494873\n",
      "Loss: 0.10740260779857635 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24757838249206543\n",
      "Loss: 0.2622698247432709 - score: (0.9409722222222222, 0.9375, 0.936186974789916, None) - t: 0.24524903297424316\n",
      "Loss: 0.1279112547636032 - score: (1.0, 1.0, 1.0, None) - t: 0.24361586570739746\n",
      "Loss: 0.11924904584884644 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2503800392150879\n",
      "Loss: 0.25531113147735596 - score: (0.96875, 0.9375, 0.95, None) - t: 0.24671673774719238\n",
      "Loss: 0.11150696873664856 - score: (1.0, 1.0, 1.0, None) - t: 0.24758625030517578\n",
      "Loss: 0.3039805293083191 - score: (0.859375, 0.875, 0.8645833333333333, None) - t: 0.2489781379699707\n",
      "Loss: 0.24079115688800812 - score: (0.859375, 0.875, 0.8645833333333334, None) - t: 0.25044870376586914\n",
      "Loss: 0.26275306940078735 - score: (0.9375, 0.9375, 0.9375, None) - t: 0.24407052993774414\n",
      "Loss: 0.1049174964427948 - score: (0.97265625, 0.96875, 0.9685897435897435, None) - t: 0.24860000610351562\n",
      "Loss: 0.36739498376846313 - score: (0.91015625, 0.90625, 0.9060897435897435, None) - t: 0.24866199493408203\n",
      "Loss: 0.20772437751293182 - score: (0.9375, 0.9375, 0.9375, None) - t: 0.2448275089263916\n",
      "Loss: 0.39767777919769287 - score: (0.9375, 0.90625, 0.9166666666666666, None) - t: 0.2485642433166504\n",
      "Loss: 0.2071237862110138 - score: (0.9427083333333334, 0.9375, 0.9382411067193677, None) - t: 0.25005102157592773\n",
      "Loss: 0.1848161816596985 - score: (0.9453125, 0.9375, 0.9389880952380951, None) - t: 0.2552943229675293\n",
      "Loss: 0.10905522108078003 - score: (0.940625, 0.96875, 0.9539473684210527, None) - t: 0.2480456829071045\n",
      "Loss: 0.4448113739490509 - score: (0.84375, 0.84375, 0.84375, None) - t: 0.24753046035766602\n",
      "Loss: 0.16579152643680573 - score: (0.9375, 0.9375, 0.9375, None) - t: 0.2421419620513916\n",
      "Loss: 0.15674397349357605 - score: (0.953125, 0.96875, 0.9583333333333334, None) - t: 0.24616265296936035\n",
      "Loss: 0.21880768239498138 - score: (1.0, 0.96875, 0.9791666666666666, None) - t: 0.24748992919921875\n",
      "Loss: 0.061611294746398926 - score: (1.0, 1.0, 1.0, None) - t: 0.24528765678405762\n",
      "Loss: 0.2230520099401474 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2452695369720459\n",
      "Loss: 0.5285331606864929 - score: (0.753125, 0.78125, 0.7581140350877194, None) - t: 0.2490251064300537\n",
      "Loss: 0.2282601296901703 - score: (0.9375, 0.9375, 0.9375, None) - t: 0.24710988998413086\n",
      "Loss: 0.15994662046432495 - score: (0.953125, 0.96875, 0.9583333333333334, None) - t: 0.24803853034973145\n",
      "Loss: 0.18811571598052979 - score: (0.9140625, 0.90625, 0.9067460317460317, None) - t: 0.24950790405273438\n",
      "Loss: 0.28935062885284424 - score: (0.90234375, 0.875, 0.8878676470588236, None) - t: 0.24646639823913574\n",
      "Loss: 0.22890996932983398 - score: (0.971875, 0.90625, 0.9256735588972431, None) - t: 0.24915409088134766\n",
      "Loss: 0.13978350162506104 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2470252513885498\n",
      "Loss: 0.33967626094818115 - score: (0.9107142857142857, 0.90625, 0.905715811965812, None) - t: 0.25257301330566406\n",
      "Loss: 0.2563997805118561 - score: (0.9375, 0.9375, 0.9375, None) - t: 0.24872612953186035\n",
      "Loss: 0.15459978580474854 - score: (0.96875, 0.9375, 0.9479166666666666, None) - t: 0.2534809112548828\n",
      "Loss: 0.2698841989040375 - score: (0.86875, 0.875, 0.8662683823529411, None) - t: 0.2532789707183838\n",
      "Loss: 0.19406023621559143 - score: (1.0, 0.9375, 0.9583333333333333, None) - t: 0.2489454746246338\n",
      "Loss: 0.26815345883369446 - score: (0.9114583333333334, 0.90625, 0.9064685314685315, None) - t: 0.25130796432495117\n",
      "Loss: 0.21904624998569489 - score: (0.9375, 0.9375, 0.9375, None) - t: 0.25442051887512207\n",
      "Loss: 0.5145576596260071 - score: (0.88125, 0.8125, 0.8333333333333333, None) - t: 0.2489161491394043\n",
      "Loss: 0.23966102302074432 - score: (0.90625, 0.90625, 0.90625, None) - t: 0.2502586841583252\n",
      "Loss: 0.24549496173858643 - score: (0.96875, 0.875, 0.9062499999999999, None) - t: 0.24697113037109375\n",
      "Loss: 0.191665917634964 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24925947189331055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 9/25 [06:03<10:39, 39.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.06699226796627045 - score: (1.0, 1.0, 1.0, None) - t: 0.21597599983215332\n",
      "Loss: 0.1255986988544464 - score: (0.96875, 0.9375, 0.9479166666666666, None) - t: 0.24900197982788086\n",
      "Loss: 0.10613685846328735 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2492363452911377\n",
      "Loss: 0.05228722095489502 - score: (1.0, 1.0, 1.0, None) - t: 0.2484602928161621\n",
      "Loss: 0.04145243763923645 - score: (1.0, 1.0, 1.0, None) - t: 0.2479393482208252\n",
      "Loss: 0.12369778752326965 - score: (1.0, 1.0, 1.0, None) - t: 0.24870538711547852\n",
      "Loss: 0.17049437761306763 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2509286403656006\n",
      "Loss: 0.13100576400756836 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24902939796447754\n",
      "Loss: 0.0510006844997406 - score: (1.0, 1.0, 1.0, None) - t: 0.25282812118530273\n",
      "Loss: 0.05005127191543579 - score: (1.0, 1.0, 1.0, None) - t: 0.25153636932373047\n",
      "Loss: 0.2562367022037506 - score: (0.875, 0.875, 0.875, None) - t: 0.24989604949951172\n",
      "Loss: 0.15731438994407654 - score: (0.984375, 0.96875, 0.9708333333333333, None) - t: 0.24819540977478027\n",
      "Loss: 0.31668904423713684 - score: (0.875, 0.875, 0.875, None) - t: 0.2493729591369629\n",
      "Loss: 0.03694278001785278 - score: (1.0, 1.0, 1.0, None) - t: 0.24883675575256348\n",
      "Loss: 0.20084895193576813 - score: (0.90625, 0.90625, 0.90625, None) - t: 0.24691128730773926\n",
      "Loss: 0.06944406032562256 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.25299620628356934\n",
      "Loss: 0.1846148669719696 - score: (0.9375, 0.90625, 0.9166666666666666, None) - t: 0.2488231658935547\n",
      "Loss: 0.08389067649841309 - score: (1.0, 1.0, 1.0, None) - t: 0.24743056297302246\n",
      "Loss: 0.21410846710205078 - score: (0.9419642857142857, 0.9375, 0.9379578754578755, None) - t: 0.2473142147064209\n",
      "Loss: 0.2673959732055664 - score: (0.91796875, 0.875, 0.8824404761904762, None) - t: 0.2482006549835205\n",
      "Loss: 0.2922399044036865 - score: (0.90625, 0.875, 0.8854166666666666, None) - t: 0.25255250930786133\n",
      "Loss: 0.24210552871227264 - score: (1.0, 0.96875, 0.9791666666666666, None) - t: 0.2495272159576416\n",
      "Loss: 0.13261649012565613 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2483692169189453\n",
      "Loss: 0.11080987751483917 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24858379364013672\n",
      "Loss: 0.11930270493030548 - score: (0.9270833333333334, 0.9375, 0.9274621212121212, None) - t: 0.25208568572998047\n",
      "Loss: 0.07242754101753235 - score: (1.0, 1.0, 1.0, None) - t: 0.25204014778137207\n",
      "Loss: 0.24974779784679413 - score: (0.9375, 0.9375, 0.9375, None) - t: 0.25279998779296875\n",
      "Loss: 0.22774416208267212 - score: (0.9166666666666666, 0.90625, 0.9081730769230769, None) - t: 0.24972128868103027\n",
      "Loss: 0.19734613597393036 - score: (0.971875, 0.9375, 0.9485902255639098, None) - t: 0.2497539520263672\n",
      "Loss: 0.18842455744743347 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.25484609603881836\n",
      "Loss: 0.10488662123680115 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2501494884490967\n",
      "Loss: 0.08701711893081665 - score: (1.0, 0.96875, 0.9791666666666666, None) - t: 0.25101542472839355\n",
      "Loss: 0.27618637681007385 - score: (0.9375, 0.9375, 0.9375, None) - t: 0.2471165657043457\n",
      "Loss: 0.27634045481681824 - score: (0.9375, 0.90625, 0.9166666666666666, None) - t: 0.2504904270172119\n",
      "Loss: 0.05887475609779358 - score: (1.0, 1.0, 1.0, None) - t: 0.24915146827697754\n",
      "Loss: 0.1428348422050476 - score: (0.921875, 0.9375, 0.9270833333333333, None) - t: 0.2619965076446533\n",
      "Loss: 0.1066889762878418 - score: (1.0, 0.96875, 0.98125, None) - t: 0.25205159187316895\n",
      "Loss: 0.2791012227535248 - score: (0.90625, 0.90625, 0.90625, None) - t: 0.24976420402526855\n",
      "Loss: 0.10501858592033386 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.25449609756469727\n",
      "Loss: 0.17319965362548828 - score: (0.9375, 0.9375, 0.9375, None) - t: 0.24685072898864746\n",
      "Loss: 0.10306079685688019 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24852347373962402\n",
      "Loss: 0.059788480401039124 - score: (1.0, 1.0, 1.0, None) - t: 0.2499251365661621\n",
      "Loss: 0.13897643983364105 - score: (0.9765625, 0.9375, 0.9489468864468863, None) - t: 0.25011754035949707\n",
      "Loss: 0.044798314571380615 - score: (1.0, 1.0, 1.0, None) - t: 0.2523629665374756\n",
      "Loss: 0.2852780520915985 - score: (0.90625, 0.875, 0.8888888888888888, None) - t: 0.2473278045654297\n",
      "Loss: 0.0826975405216217 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.25044918060302734\n",
      "Loss: 0.06932118535041809 - score: (1.0, 1.0, 1.0, None) - t: 0.2501943111419678\n",
      "Loss: 0.15322017669677734 - score: (0.97265625, 0.9375, 0.9385416666666666, None) - t: 0.24868321418762207\n",
      "Loss: 0.2408873587846756 - score: (0.9375, 0.90625, 0.9166666666666666, None) - t: 0.2513251304626465\n",
      "Loss: 0.13345910608768463 - score: (1.0, 0.96875, 0.9821428571428572, None) - t: 0.2485976219177246\n",
      "Loss: 0.14365509152412415 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2532947063446045\n",
      "Loss: 0.21580222249031067 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2492964267730713\n",
      "Loss: 0.20714625716209412 - score: (0.94140625, 0.90625, 0.9192640692640692, None) - t: 0.2535877227783203\n",
      "Loss: 0.08396592736244202 - score: (1.0, 1.0, 1.0, None) - t: 0.2460622787475586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 10/25 [06:41<09:49, 39.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.08198501169681549 - score: (1.0, 1.0, 1.0, None) - t: 0.21700000762939453\n",
      "Loss: 0.11997118592262268 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24536657333374023\n",
      "Loss: 0.03383883833885193 - score: (1.0, 1.0, 1.0, None) - t: 0.24517226219177246\n",
      "Loss: 0.1517198085784912 - score: (0.9140625, 0.9375, 0.9241071428571428, None) - t: 0.251049280166626\n",
      "Loss: 0.064372718334198 - score: (1.0, 1.0, 1.0, None) - t: 0.25250887870788574\n",
      "Loss: 0.10813972353935242 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2534759044647217\n",
      "Loss: 0.04991424083709717 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24783754348754883\n",
      "Loss: 0.08174008131027222 - score: (1.0, 1.0, 1.0, None) - t: 0.24945425987243652\n",
      "Loss: 0.06963041424751282 - score: (0.975, 0.96875, 0.9690656565656566, None) - t: 0.24779033660888672\n",
      "Loss: 0.0288560688495636 - score: (1.0, 1.0, 1.0, None) - t: 0.2524435520172119\n",
      "Loss: 0.15585142374038696 - score: (0.9375, 0.9375, 0.9375, None) - t: 0.255598783493042\n",
      "Loss: 0.17243815958499908 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2558910846710205\n",
      "Loss: 0.04396963119506836 - score: (1.0, 1.0, 1.0, None) - t: 0.2503855228424072\n",
      "Loss: 0.05083194375038147 - score: (1.0, 1.0, 1.0, None) - t: 0.2486872673034668\n",
      "Loss: 0.12972018122673035 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24776053428649902\n",
      "Loss: 0.1813790649175644 - score: (0.9375, 0.9375, 0.9375, None) - t: 0.2510528564453125\n",
      "Loss: 0.04899832606315613 - score: (1.0, 1.0, 1.0, None) - t: 0.24965858459472656\n",
      "Loss: 0.3465859889984131 - score: (0.890625, 0.90625, 0.8958333333333333, None) - t: 0.25567102432250977\n",
      "Loss: 0.19151675701141357 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2518925666809082\n",
      "Loss: 0.07692277431488037 - score: (1.0, 0.96875, 0.9791666666666666, None) - t: 0.2552049160003662\n",
      "Loss: 0.04958897829055786 - score: (1.0, 1.0, 1.0, None) - t: 0.2539384365081787\n",
      "Loss: 0.04191035032272339 - score: (1.0, 1.0, 1.0, None) - t: 0.251697301864624\n",
      "Loss: 0.03648245334625244 - score: (1.0, 1.0, 1.0, None) - t: 0.25557780265808105\n",
      "Loss: 0.0824316143989563 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2467508316040039\n",
      "Loss: 0.14049303531646729 - score: (0.9114583333333334, 0.9375, 0.9232954545454546, None) - t: 0.24922561645507812\n",
      "Loss: 0.19731411337852478 - score: (0.96875, 0.9375, 0.9479166666666666, None) - t: 0.24695706367492676\n",
      "Loss: 0.06288608908653259 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24727773666381836\n",
      "Loss: 0.1255810260772705 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.25038647651672363\n",
      "Loss: 0.19944922626018524 - score: (0.890625, 0.90625, 0.8958333333333334, None) - t: 0.24866247177124023\n",
      "Loss: 0.11378519237041473 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2510371208190918\n",
      "Loss: 0.061353832483291626 - score: (0.971875, 0.96875, 0.968530701754386, None) - t: 0.25057435035705566\n",
      "Loss: 0.23855344951152802 - score: (0.8697916666666666, 0.90625, 0.8833333333333333, None) - t: 0.24828338623046875\n",
      "Loss: 0.059371888637542725 - score: (1.0, 1.0, 1.0, None) - t: 0.24731659889221191\n",
      "Loss: 0.281398743391037 - score: (0.875, 0.875, 0.875, None) - t: 0.2496950626373291\n",
      "Loss: 0.05970314145088196 - score: (1.0, 1.0, 1.0, None) - t: 0.24846744537353516\n",
      "Loss: 0.07792806625366211 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24543094635009766\n",
      "Loss: 0.17029643058776855 - score: (0.90625, 0.90625, 0.90625, None) - t: 0.24970507621765137\n",
      "Loss: 0.11443737149238586 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24478769302368164\n",
      "Loss: 0.07943081855773926 - score: (1.0, 1.0, 1.0, None) - t: 0.24457049369812012\n",
      "Loss: 0.08368875086307526 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.25014257431030273\n",
      "Loss: 0.34710365533828735 - score: (0.875, 0.875, 0.875, None) - t: 0.2519252300262451\n",
      "Loss: 0.1353926658630371 - score: (0.9375, 0.9375, 0.9375, None) - t: 0.24977397918701172\n",
      "Loss: 0.14898793399333954 - score: (0.9427083333333334, 0.9375, 0.9337121212121211, None) - t: 0.24774527549743652\n",
      "Loss: 0.05879297852516174 - score: (0.975, 0.96875, 0.9696637426900585, None) - t: 0.2463080883026123\n",
      "Loss: 0.2511894702911377 - score: (0.8854166666666667, 0.875, 0.8729166666666667, None) - t: 0.24735760688781738\n",
      "Loss: 0.17296020686626434 - score: (0.890625, 0.90625, 0.8958333333333334, None) - t: 0.2449491024017334\n",
      "Loss: 0.14582034945487976 - score: (0.9125, 0.9375, 0.9236111111111112, None) - t: 0.24515843391418457\n",
      "Loss: 0.03837108612060547 - score: (1.0, 1.0, 1.0, None) - t: 0.24547314643859863\n",
      "Loss: 0.08491933345794678 - score: (1.0, 1.0, 1.0, None) - t: 0.24526500701904297\n",
      "Loss: 0.17600081861019135 - score: (1.0, 0.9375, 0.9583333333333333, None) - t: 0.24720120429992676\n",
      "Loss: 0.10078132152557373 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24904656410217285\n",
      "Loss: 0.07579565048217773 - score: (1.0, 1.0, 1.0, None) - t: 0.24721884727478027\n",
      "Loss: 0.1320156753063202 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24618268013000488\n",
      "Loss: 0.0748094916343689 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24707341194152832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 11/25 [07:19<09:05, 38.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.18772754073143005 - score: (0.9655172413793104, 0.9655172413793104, 0.9655172413793104, None) - t: 0.21920514106750488\n",
      "Loss: 0.06538054347038269 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2435166835784912\n",
      "Loss: 0.0352228581905365 - score: (1.0, 1.0, 1.0, None) - t: 0.24964332580566406\n",
      "Loss: 0.1934482455253601 - score: (0.9375, 0.9375, 0.9375, None) - t: 0.24395346641540527\n",
      "Loss: 0.04766830801963806 - score: (1.0, 1.0, 1.0, None) - t: 0.24714279174804688\n",
      "Loss: 0.12364715337753296 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2480325698852539\n",
      "Loss: 0.04656180739402771 - score: (1.0, 1.0, 1.0, None) - t: 0.25034666061401367\n",
      "Loss: 0.04773804545402527 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24703264236450195\n",
      "Loss: 0.07963374257087708 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2487959861755371\n",
      "Loss: 0.06457695364952087 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24413824081420898\n",
      "Loss: 0.10430148243904114 - score: (1.0, 0.96875, 0.9791666666666666, None) - t: 0.24245095252990723\n",
      "Loss: 0.13316941261291504 - score: (1.0, 0.96875, 0.9821428571428572, None) - t: 0.2540168762207031\n",
      "Loss: 0.086280956864357 - score: (1.0, 0.96875, 0.98125, None) - t: 0.2542273998260498\n",
      "Loss: 0.03150787949562073 - score: (1.0, 1.0, 1.0, None) - t: 0.24505305290222168\n",
      "Loss: 0.11751008033752441 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.25049567222595215\n",
      "Loss: 0.02583688497543335 - score: (1.0, 1.0, 1.0, None) - t: 0.2445507049560547\n",
      "Loss: 0.11500740051269531 - score: (0.9427083333333334, 0.9375, 0.9377185314685315, None) - t: 0.245009183883667\n",
      "Loss: 0.061484575271606445 - score: (1.0, 1.0, 1.0, None) - t: 0.24583220481872559\n",
      "Loss: 0.0893486738204956 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2513427734375\n",
      "Loss: 0.08324253559112549 - score: (1.0, 0.96875, 0.9791666666666666, None) - t: 0.2501544952392578\n",
      "Loss: 0.034897565841674805 - score: (1.0, 1.0, 1.0, None) - t: 0.2457118034362793\n",
      "Loss: 0.10936787724494934 - score: (0.953125, 0.9375, 0.9375, None) - t: 0.24472904205322266\n",
      "Loss: 0.04044449329376221 - score: (1.0, 1.0, 1.0, None) - t: 0.24898838996887207\n",
      "Loss: 0.06850200891494751 - score: (1.0, 1.0, 1.0, None) - t: 0.24495959281921387\n",
      "Loss: 0.13723787665367126 - score: (1.0, 0.96875, 0.9791666666666666, None) - t: 0.2439866065979004\n",
      "Loss: 0.08506827056407928 - score: (1.0, 0.96875, 0.9833333333333334, None) - t: 0.2514047622680664\n",
      "Loss: 0.23656810820102692 - score: (0.96875, 0.9375, 0.9479166666666666, None) - t: 0.244553804397583\n",
      "Loss: 0.11850807070732117 - score: (0.96875, 0.9375, 0.9522058823529411, None) - t: 0.25081562995910645\n",
      "Loss: 0.05162295699119568 - score: (0.975, 0.96875, 0.9694444444444444, None) - t: 0.2465500831604004\n",
      "Loss: 0.05309736728668213 - score: (1.0, 1.0, 1.0, None) - t: 0.2500748634338379\n",
      "Loss: 0.30481910705566406 - score: (0.90625, 0.90625, 0.90625, None) - t: 0.2460930347442627\n",
      "Loss: 0.11376741528511047 - score: (0.9409722222222222, 0.9375, 0.936186974789916, None) - t: 0.25150609016418457\n",
      "Loss: 0.025152087211608887 - score: (1.0, 1.0, 1.0, None) - t: 0.24788331985473633\n",
      "Loss: 0.040596455335617065 - score: (1.0, 1.0, 1.0, None) - t: 0.24530911445617676\n",
      "Loss: 0.02143433690071106 - score: (1.0, 1.0, 1.0, None) - t: 0.24539899826049805\n",
      "Loss: 0.022064536809921265 - score: (1.0, 1.0, 1.0, None) - t: 0.24419856071472168\n",
      "Loss: 0.22297188639640808 - score: (0.9375, 0.9375, 0.9375, None) - t: 0.24764132499694824\n",
      "Loss: 0.04794585704803467 - score: (1.0, 1.0, 1.0, None) - t: 0.24382758140563965\n",
      "Loss: 0.02428257465362549 - score: (1.0, 1.0, 1.0, None) - t: 0.24558663368225098\n",
      "Loss: 0.21771612763404846 - score: (0.890625, 0.875, 0.875, None) - t: 0.2465507984161377\n",
      "Loss: 0.19233766198158264 - score: (1.0, 0.9375, 0.9618055555555556, None) - t: 0.24700617790222168\n",
      "Loss: 0.04941055178642273 - score: (1.0, 1.0, 1.0, None) - t: 0.24768781661987305\n",
      "Loss: 0.1770440638065338 - score: (0.96875, 0.9375, 0.9479166666666666, None) - t: 0.2524266242980957\n",
      "Loss: 0.10753649473190308 - score: (0.97265625, 0.96875, 0.9645833333333333, None) - t: 0.2509644031524658\n",
      "Loss: 0.10596835613250732 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24863266944885254\n",
      "Loss: 0.15524770319461823 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2463517189025879\n",
      "Loss: 0.1824624091386795 - score: (1.0, 0.9375, 0.953125, None) - t: 0.2462005615234375\n",
      "Loss: 0.10461737215518951 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2472972869873047\n",
      "Loss: 0.21233467757701874 - score: (0.9765625, 0.9375, 0.9493264411027569, None) - t: 0.2508065700531006\n",
      "Loss: 0.15112373232841492 - score: (0.93125, 0.90625, 0.91015625, None) - t: 0.24583983421325684\n",
      "Loss: 0.03815796971321106 - score: (1.0, 1.0, 1.0, None) - t: 0.24979043006896973\n",
      "Loss: 0.07558515667915344 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24507737159729004\n",
      "Loss: 0.27857035398483276 - score: (0.90625, 0.90625, 0.90625, None) - t: 0.24633502960205078\n",
      "Loss: 0.020071029663085938 - score: (1.0, 1.0, 1.0, None) - t: 0.24890565872192383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 12/25 [08:02<08:42, 40.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.12307015806436539 - score: (0.9482758620689655, 0.9655172413793104, 0.9540229885057471, None) - t: 0.21663522720336914\n",
      "Loss: 0.03420951962471008 - score: (1.0, 1.0, 1.0, None) - t: 0.24928808212280273\n",
      "Loss: 0.09547868371009827 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24723267555236816\n",
      "Loss: 0.061547279357910156 - score: (1.0, 0.96875, 0.9791666666666666, None) - t: 0.24667692184448242\n",
      "Loss: 0.07579755783081055 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24834275245666504\n",
      "Loss: 0.0706055760383606 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24505925178527832\n",
      "Loss: 0.09219726920127869 - score: (0.953125, 0.96875, 0.9583333333333333, None) - t: 0.24703240394592285\n",
      "Loss: 0.015090852975845337 - score: (1.0, 1.0, 1.0, None) - t: 0.24846935272216797\n",
      "Loss: 0.050667911767959595 - score: (0.953125, 0.96875, 0.9583333333333333, None) - t: 0.2546577453613281\n",
      "Loss: 0.02308604121208191 - score: (1.0, 1.0, 1.0, None) - t: 0.25429677963256836\n",
      "Loss: 0.05750301480293274 - score: (0.9722222222222222, 0.96875, 0.967436974789916, None) - t: 0.2497086524963379\n",
      "Loss: 0.03950640559196472 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.25525617599487305\n",
      "Loss: 0.019771814346313477 - score: (1.0, 1.0, 1.0, None) - t: 0.2530210018157959\n",
      "Loss: 0.07644866406917572 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.25078392028808594\n",
      "Loss: 0.05923590064048767 - score: (1.0, 1.0, 1.0, None) - t: 0.24606680870056152\n",
      "Loss: 0.10095211863517761 - score: (1.0, 0.96875, 0.9791666666666666, None) - t: 0.247542142868042\n",
      "Loss: 0.10272234678268433 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24684739112854004\n",
      "Loss: 0.04808869957923889 - score: (0.9765625, 0.96875, 0.9701597744360902, None) - t: 0.24581003189086914\n",
      "Loss: 0.23697501420974731 - score: (0.890625, 0.90625, 0.8958333333333333, None) - t: 0.2520477771759033\n",
      "Loss: 0.12439179420471191 - score: (0.953125, 0.96875, 0.9583333333333334, None) - t: 0.2481522560119629\n",
      "Loss: 0.07268157601356506 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.251645565032959\n",
      "Loss: 0.0541650652885437 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24854063987731934\n",
      "Loss: 0.04667380452156067 - score: (1.0, 1.0, 1.0, None) - t: 0.2462766170501709\n",
      "Loss: 0.1290120929479599 - score: (1.0, 0.96875, 0.9791666666666666, None) - t: 0.2514340877532959\n",
      "Loss: 0.021130621433258057 - score: (1.0, 1.0, 1.0, None) - t: 0.25086092948913574\n",
      "Loss: 0.08530253171920776 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24788546562194824\n",
      "Loss: 0.12372183799743652 - score: (0.94140625, 0.9375, 0.9371212121212121, None) - t: 0.24731850624084473\n",
      "Loss: 0.03959581255912781 - score: (1.0, 1.0, 1.0, None) - t: 0.2515683174133301\n",
      "Loss: 0.05357825756072998 - score: (1.0, 1.0, 1.0, None) - t: 0.24913716316223145\n",
      "Loss: 0.03393346071243286 - score: (1.0, 1.0, 1.0, None) - t: 0.2510702610015869\n",
      "Loss: 0.07731661200523376 - score: (0.9732142857142857, 0.96875, 0.9689102564102565, None) - t: 0.2481689453125\n",
      "Loss: 0.12137316167354584 - score: (0.9375, 0.9375, 0.9375, None) - t: 0.24843144416809082\n",
      "Loss: 0.14620308578014374 - score: (0.9732142857142857, 0.9375, 0.9501602564102565, None) - t: 0.25098204612731934\n",
      "Loss: 0.14128074049949646 - score: (0.9375, 0.9375, 0.9375, None) - t: 0.24599385261535645\n",
      "Loss: 0.13457325100898743 - score: (0.953125, 0.96875, 0.9583333333333333, None) - t: 0.25000619888305664\n",
      "Loss: 0.058183908462524414 - score: (0.984375, 0.96875, 0.96875, None) - t: 0.2520875930786133\n",
      "Loss: 0.0943930596113205 - score: (1.0, 0.96875, 0.9791666666666666, None) - t: 0.24669837951660156\n",
      "Loss: 0.0992104560136795 - score: (1.0, 0.96875, 0.98125, None) - t: 0.24784326553344727\n",
      "Loss: 0.03184676170349121 - score: (1.0, 1.0, 1.0, None) - t: 0.25205016136169434\n",
      "Loss: 0.18606862425804138 - score: (0.8697916666666666, 0.90625, 0.8802083333333333, None) - t: 0.24725103378295898\n",
      "Loss: 0.06675344705581665 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24926280975341797\n",
      "Loss: 0.04656389355659485 - score: (1.0, 1.0, 1.0, None) - t: 0.25095248222351074\n",
      "Loss: 0.12045726180076599 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2512338161468506\n",
      "Loss: 0.09390081465244293 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24865460395812988\n",
      "Loss: 0.17726320028305054 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.25024986267089844\n",
      "Loss: 0.1104668378829956 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24754095077514648\n",
      "Loss: 0.05719029903411865 - score: (1.0, 0.96875, 0.9821428571428572, None) - t: 0.24706077575683594\n",
      "Loss: 0.025097399950027466 - score: (1.0, 1.0, 1.0, None) - t: 0.25118517875671387\n",
      "Loss: 0.04005718231201172 - score: (1.0, 1.0, 1.0, None) - t: 0.24358463287353516\n",
      "Loss: 0.3278410732746124 - score: (0.859375, 0.875, 0.8645833333333334, None) - t: 0.24688458442687988\n",
      "Loss: 0.10274946689605713 - score: (1.0, 0.96875, 0.9791666666666666, None) - t: 0.25371789932250977\n",
      "Loss: 0.08764687180519104 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.25354623794555664\n",
      "Loss: 0.06712210178375244 - score: (1.0, 0.96875, 0.9821428571428572, None) - t: 0.250169038772583\n",
      "Loss: 0.1890154629945755 - score: (0.9375, 0.9375, 0.9375, None) - t: 0.2552225589752197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 13/25 [08:41<07:58, 39.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1816045492887497 - score: (0.9359605911330049, 0.9310344827586207, 0.930793344586448, None) - t: 0.21824860572814941\n",
      "Loss: 0.12877006828784943 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24834036827087402\n",
      "Loss: 0.07056084275245667 - score: (1.0, 0.96875, 0.98125, None) - t: 0.254910945892334\n",
      "Loss: 0.061870574951171875 - score: (0.9732142857142857, 0.96875, 0.9689102564102564, None) - t: 0.25023460388183594\n",
      "Loss: 0.12833629548549652 - score: (1.0, 0.96875, 0.9791666666666666, None) - t: 0.25290727615356445\n",
      "Loss: 0.03703814744949341 - score: (1.0, 1.0, 1.0, None) - t: 0.2543973922729492\n",
      "Loss: 0.11107541620731354 - score: (0.9375, 0.9375, 0.9375, None) - t: 0.25595808029174805\n",
      "Loss: 0.026928424835205078 - score: (1.0, 1.0, 1.0, None) - t: 0.2524862289428711\n",
      "Loss: 0.033330559730529785 - score: (1.0, 1.0, 1.0, None) - t: 0.2510077953338623\n",
      "Loss: 0.050582826137542725 - score: (1.0, 1.0, 1.0, None) - t: 0.24727201461791992\n",
      "Loss: 0.06021009385585785 - score: (1.0, 1.0, 1.0, None) - t: 0.2506856918334961\n",
      "Loss: 0.019968539476394653 - score: (1.0, 1.0, 1.0, None) - t: 0.2506382465362549\n",
      "Loss: 0.07248839735984802 - score: (0.984375, 0.96875, 0.9732789855072463, None) - t: 0.2545316219329834\n",
      "Loss: 0.04298141598701477 - score: (1.0, 1.0, 1.0, None) - t: 0.2508728504180908\n",
      "Loss: 0.08909785747528076 - score: (0.921875, 0.9375, 0.9270833333333333, None) - t: 0.24907708168029785\n",
      "Loss: 0.1048872172832489 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24744153022766113\n",
      "Loss: 0.02186325192451477 - score: (1.0, 1.0, 1.0, None) - t: 0.24940800666809082\n",
      "Loss: 0.07546712458133698 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2527458667755127\n",
      "Loss: 0.03767925500869751 - score: (1.0, 1.0, 1.0, None) - t: 0.25666046142578125\n",
      "Loss: 0.10651308298110962 - score: (1.0, 0.96875, 0.9791666666666666, None) - t: 0.25173306465148926\n",
      "Loss: 0.01707252860069275 - score: (1.0, 1.0, 1.0, None) - t: 0.25513529777526855\n",
      "Loss: 0.03593182563781738 - score: (1.0, 1.0, 1.0, None) - t: 0.2490699291229248\n",
      "Loss: 0.05899345874786377 - score: (1.0, 1.0, 1.0, None) - t: 0.2528963088989258\n",
      "Loss: 0.11479246616363525 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2543020248413086\n",
      "Loss: 0.02222299575805664 - score: (1.0, 1.0, 1.0, None) - t: 0.2598385810852051\n",
      "Loss: 0.06586652994155884 - score: (1.0, 1.0, 1.0, None) - t: 0.2512176036834717\n",
      "Loss: 0.029303431510925293 - score: (1.0, 1.0, 1.0, None) - t: 0.24963879585266113\n",
      "Loss: 0.12657487392425537 - score: (0.9419642857142857, 0.9375, 0.9376602564102564, None) - t: 0.25464391708374023\n",
      "Loss: 0.15081201493740082 - score: (0.9375, 0.9375, 0.9375, None) - t: 0.25409984588623047\n",
      "Loss: 0.028176873922348022 - score: (1.0, 1.0, 1.0, None) - t: 0.25093936920166016\n",
      "Loss: 0.1422741711139679 - score: (0.9583333333333334, 0.9375, 0.9395833333333333, None) - t: 0.24660491943359375\n",
      "Loss: 0.0176946222782135 - score: (1.0, 1.0, 1.0, None) - t: 0.24690771102905273\n",
      "Loss: 0.08507409691810608 - score: (0.953125, 0.96875, 0.9583333333333333, None) - t: 0.24982786178588867\n",
      "Loss: 0.10297051072120667 - score: (0.921875, 0.9375, 0.9270833333333333, None) - t: 0.25400519371032715\n",
      "Loss: 0.014799296855926514 - score: (1.0, 1.0, 1.0, None) - t: 0.2509334087371826\n",
      "Loss: 0.012946754693984985 - score: (1.0, 1.0, 1.0, None) - t: 0.2489795684814453\n",
      "Loss: 0.09037350118160248 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24669098854064941\n",
      "Loss: 0.16811303794384003 - score: (0.9375, 0.90625, 0.91875, None) - t: 0.2478775978088379\n",
      "Loss: 0.2921927869319916 - score: (0.953125, 0.9375, 0.9375, None) - t: 0.24967432022094727\n",
      "Loss: 0.027003169059753418 - score: (1.0, 1.0, 1.0, None) - t: 0.24471759796142578\n",
      "Loss: 0.11761096119880676 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2469310760498047\n",
      "Loss: 0.08659404516220093 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24881219863891602\n",
      "Loss: 0.028837203979492188 - score: (1.0, 1.0, 1.0, None) - t: 0.2519214153289795\n",
      "Loss: 0.03562760353088379 - score: (1.0, 1.0, 1.0, None) - t: 0.2456068992614746\n",
      "Loss: 0.06299489736557007 - score: (1.0, 1.0, 1.0, None) - t: 0.250490665435791\n",
      "Loss: 0.06649214029312134 - score: (0.9739583333333334, 0.96875, 0.9689685314685315, None) - t: 0.2518036365509033\n",
      "Loss: 0.0861329436302185 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24994754791259766\n",
      "Loss: 0.11808799207210541 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.249769926071167\n",
      "Loss: 0.042237669229507446 - score: (1.0, 1.0, 1.0, None) - t: 0.24672484397888184\n",
      "Loss: 0.09994804859161377 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.2496647834777832\n",
      "Loss: 0.0480310320854187 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24824857711791992\n",
      "Loss: 0.02871677279472351 - score: (1.0, 1.0, 1.0, None) - t: 0.24657440185546875\n",
      "Loss: 0.017127543687820435 - score: (1.0, 1.0, 1.0, None) - t: 0.24838972091674805\n",
      "Loss: 0.11403805017471313 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.24800920486450195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 14/25 [09:27<07:38, 41.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.09191510081291199 - score: (1.0, 0.9655172413793104, 0.981609195402299, None) - t: 0.21768689155578613\n",
      "Loss: 0.03647094964981079 - score: (1.0, 1.0, 1.0, None) - t: 0.25031423568725586\n",
      "Loss: 0.03871944546699524 - score: (1.0, 1.0, 1.0, None) - t: 0.2462151050567627\n",
      "Loss: 0.04218283295631409 - score: (1.0, 1.0, 1.0, None) - t: 0.24758625030517578\n",
      "Loss: 0.042114078998565674 - score: (1.0, 1.0, 1.0, None) - t: 0.2484893798828125\n",
      "Loss: 0.038497358560562134 - score: (1.0, 1.0, 1.0, None) - t: 0.24848079681396484\n",
      "Loss: 0.022426187992095947 - score: (1.0, 1.0, 1.0, None) - t: 0.2500476837158203\n",
      "Loss: 0.10148191452026367 - score: (0.9419642857142857, 0.9375, 0.9379578754578755, None) - t: 0.24740123748779297\n",
      "Loss: 0.08760307729244232 - score: (0.96875, 0.96875, 0.96875, None) - t: 0.25130605697631836\n",
      "Loss: 0.022877246141433716 - score: (1.0, 1.0, 1.0, None) - t: 0.24778532981872559\n",
      "Loss: 0.07037971913814545 - score: (0.984375, 0.96875, 0.96875, None) - t: 0.2473127841949463\n",
      "Loss: 0.1187267154455185 - score: (0.9479166666666666, 0.96875, 0.95625, None) - t: 0.251983642578125\n",
      "Loss: 0.019076377153396606 - score: (1.0, 1.0, 1.0, None) - t: 0.24742531776428223\n",
      "Loss: 0.04449540376663208 - score: (1.0, 1.0, 1.0, None) - t: 0.24892568588256836\n",
      "Loss: 0.02609729766845703 - score: (1.0, 1.0, 1.0, None) - t: 0.24631905555725098\n",
      "Loss: 0.023915380239486694 - score: (1.0, 1.0, 1.0, None) - t: 0.25086116790771484\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6800f6e32bea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                      \u001b[0mtraining\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                      \u001b[0mtotal_loss_over_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss_over_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                                      scores_over_epochs     = scores_over_epochs)\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#     train_scores = metrics.precision_recall_fscore_support(tr_labels,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-460ef9dc0c0c>\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(data_loader, model, criterion, optimizer, batch_size, training, total_loss_over_epochs, scores_over_epochs)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;31m# extract minibatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Visual-Question-Answering/data_loader.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0mquestion_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquestion_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0mv\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m             \u001b[0mq\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mquestion_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0ma\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0manswer_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Visual-Question-Answering/utils.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(path, transform)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"IMG_LOAD_ERR - Image File idx={}: [{}] not found\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box)\u001b[0m\n\u001b[1;32m   1802\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1804\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader = dataset.build_data_loader(train=True, args={'batch_size': batch_size})\n",
    "test_loader  = dataset.build_data_loader(test=True, args={'batch_size': batch_size})\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "train_all_loss, train_all_labels, train_all_preds = [], [], []\n",
    "\n",
    "total_loss_over_epochs, scores_over_epochs = plotting.get_empty_stat_over_n_epoch_dictionaries()\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    t0= time.time()\n",
    "    tr_loss, tr_labels, tr_preds = eval_model(data_loader = train_loader,\n",
    "                                     model       = model,\n",
    "                                     criterion   = criterion,\n",
    "                                     optimizer   = optimizer,\n",
    "                                     batch_size  = batch_size,\n",
    "                                     training    = True,\n",
    "                                     total_loss_over_epochs = total_loss_over_epochs,\n",
    "                                     scores_over_epochs     = scores_over_epochs)\n",
    "    \n",
    "#     train_scores = metrics.precision_recall_fscore_support(tr_labels,\n",
    "#                                                            tr_preds,\n",
    "#                                                            average='weighted')\n",
    "    \n",
    "#     total_loss_over_epochs['train_loss'].append(tr_loss)\n",
    "#     scores_over_epochs['train_scores'].append(train_scores)\n",
    "    \n",
    "#     if True:# or epoch%1 == 0:\n",
    "#         print(\"#==#\"*5 + \"epoch: {}\".format(epoch) + \"#==#\"*5)\n",
    "#         print(\"time: {}\".format(time.time()-t0))\n",
    "#         print(train_scores)\n",
    "#     plotting.plot_score_over_n_epochs(scores_over_epochs, score_type='precision', fig_size=(8,5))\n",
    "#     plotting.plot_loss_over_n_epochs(total_loss_over_epochs, fig_size=(8, 5), title=\"Loss\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tr_labels))\n",
    "print(type(tr_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tr_labels[0])\n",
    "print(tr_preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py361",
   "language": "python",
   "name": "py361"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
