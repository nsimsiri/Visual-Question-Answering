{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = 5000\n",
    "\n",
    "f_name = 'processed_data/data_%d.json' % (num_data)\n",
    "\n",
    "with open(f_name, 'rb') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ques_id': 448309007,\n",
       "  'img_path': 'val2014/COCO_val2014_000000448309.jpg',\n",
       "  'question': \"what kind of plant is the table's centerpiece?\",\n",
       "  'question_type': 'what kind of',\n",
       "  'ann': 'fern'},\n",
       " {'ques_id': 58254000,\n",
       "  'img_path': 'val2014/COCO_val2014_000000058254.jpg',\n",
       "  'question': 'what is it pointing at?',\n",
       "  'question_type': 'what is',\n",
       "  'ann': 'tv'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_ques_build_vocab(data, vocab, ans_vocab, max_length=20):\n",
    "    \n",
    "    quess_length = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        ques = data[i]['question']\n",
    "        ques_tokens = word_tokenize(ques)\n",
    "        \n",
    "        # with <start> and <end>\n",
    "        quess_length.append(len(ques_tokens) + 2)\n",
    "        \n",
    "        ques_tokens = ['<start>'] + ques_tokens\n",
    "        \n",
    "        while len(ques_tokens) < max_length - 1:\n",
    "            ques_tokens += ['<pad>']\n",
    "        \n",
    "        ques_tokens += ['<end>']        \n",
    "        \n",
    "        data[i]['ques_tokens'] = ques_tokens\n",
    "                \n",
    "        for w in ques_tokens:\n",
    "            vocab.add(w)\n",
    "        \n",
    "        ans_vocab.add(data[i]['ann'])\n",
    "    \n",
    "    return data, vocab, ans_vocab, quess_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(['<start>', '<end>', '<unk>', '<pad>'])\n",
    "ans_vocab = set()\n",
    "data, vocab, ans_vocab, quess_length = token_ques_build_vocab(data, vocab, ans_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtoi = {w: i+1 for i, w in enumerate(vocab)}\n",
    "itow = {i+1: w for i, w in enumerate(vocab)}\n",
    "\n",
    "atoi = {w: i for i, w in enumerate(ans_vocab)}\n",
    "itoa = {i: w for i, w in enumerate(ans_vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_ques_ann(data, wtoi):\n",
    "    \n",
    "    processed_quess = []\n",
    "    processed_anns = []\n",
    "    img_pathes = []\n",
    "        \n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        ques_tokens = data[i]['ques_tokens']\n",
    "        ques_encode = [wtoi[w] for w in ques_tokens]\n",
    "                \n",
    "        processed_quess.append(ques_encode)\n",
    "        \n",
    "        processed_anns.append(atoi[data[i]['ann']])\n",
    "        \n",
    "        img_pathes.append(data[i]['img_path'])\n",
    "                \n",
    "    return processed_quess, processed_anns, img_pathes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 20), (5000,), (5000,), (5000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_quess, processed_anns, img_pathes = encode_ques_ann(data, wtoi)\n",
    "\n",
    "processed_quess = np.array(processed_quess)\n",
    "processed_anns = np.array(processed_anns)\n",
    "img_pathes = np.array(img_pathes)\n",
    "\n",
    "quess_length = np.array(quess_length)\n",
    "\n",
    "processed_quess.shape, processed_anns.shape, img_pathes.shape, quess_length.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_per, val_per, test_per = int(num_data * 0.8), int(num_data * 0.995), num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_quess, val_quess, test_quess, _ = np.split(processed_quess, [train_per, val_per, test_per])\n",
    "\n",
    "train_anns, val_anns, test_anns, _ = np.split(processed_anns, [train_per, val_per, test_per])\n",
    "\n",
    "train_img_pathes, val_img_pathes, test_img_pathes, _ = np.split(img_pathes, [train_per, val_per, test_per])\n",
    "\n",
    "train_quess_length, val_quess_length, test_quess_length, _ = np.split(quess_length, [train_per, val_per, test_per])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000, 20), (975, 20), (25, 20))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_quess.shape, val_quess.shape, test_quess.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000,), (975,), (25,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_anns.shape, val_anns.shape, test_anns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000,), (975,), (25,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img_pathes.shape, val_img_pathes.shape, test_img_pathes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000,), (975,), (25,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_quess_length.shape, val_quess_length.shape, test_quess_length.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "\n",
    "with open('processed_data/train/train_quess_%d.pkl' % (len(train_quess)), 'wb') as f:\n",
    "    pickle.dump(train_quess, f)\n",
    "    \n",
    "with open('processed_data/train/train_anns_%d.pkl' % (len(train_anns)), 'wb') as f:\n",
    "    pickle.dump(train_anns, f)\n",
    "\n",
    "with open('processed_data/train/train_imgs_path_%d.pkl' % (len(train_img_pathes)), 'wb') as f:\n",
    "    pickle.dump(train_img_pathes, f)\n",
    "    \n",
    "with open('processed_data/train/train_quess_length_%d.pkl' % (len(train_quess_length)), 'wb') as f:\n",
    "    pickle.dump(train_quess_length, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Val data\n",
    "\n",
    "with open('processed_data/val/train_quess_%d.pkl' % (len(val_quess)), 'wb') as f:\n",
    "    pickle.dump(val_quess, f)\n",
    "    \n",
    "with open('processed_data/val/train_anns_%d.pkl' % (len(val_anns)), 'wb') as f:\n",
    "    pickle.dump(val_anns, f)\n",
    "\n",
    "with open('processed_data/val/train_imgs_path_%d.pkl'% (len(val_img_pathes)), 'wb') as f:\n",
    "    pickle.dump(val_img_pathes, f)\n",
    "    \n",
    "with open('processed_data/val/val_quess_length_%d.pkl'% (len(val_quess_length)), 'wb') as f:\n",
    "    pickle.dump(val_quess_length, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "\n",
    "with open('processed_data/test/train_quess_%d.pkl' % (len(test_quess)), 'wb') as f:\n",
    "    pickle.dump(test_quess, f)\n",
    "    \n",
    "with open('processed_data/test/train_anns_%d.pkl' % (len(test_anns)), 'wb') as f:\n",
    "    pickle.dump(test_anns, f)\n",
    "\n",
    "with open('processed_data/test/train_imgs_path_%d.pkl' % (len(test_img_pathes)), 'wb') as f:\n",
    "    pickle.dump(test_img_pathes, f)\n",
    "    \n",
    "with open('processed_data/test/test_quess_length_%d.pkl' % (len(test_quess_length)), 'wb') as f:\n",
    "    pickle.dump(test_quess_length, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wtoi, itow, ans_vocab, #train, #val, #test\n",
    "\n",
    "with open('processed_data/utility.pkl', 'wb') as f:\n",
    "    pickle.dump([wtoi, itow, atoi, itoa, len(train_quess), len(val_quess), len(test_quess)], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
